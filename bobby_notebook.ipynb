{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\42ben\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"tweets.csv\", encoding='latin1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iPad                               946\n",
       "Apple                              661\n",
       "iPad or iPhone App                 470\n",
       "Google                             430\n",
       "iPhone                             297\n",
       "Other Google product or service    293\n",
       "Android App                         81\n",
       "Android                             78\n",
       "Other Apple product or service      35\n",
       "Name: emotion_in_tweet_is_directed_at, dtype: int64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['emotion_in_tweet_is_directed_at'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    5389\n",
       "Positive emotion                      2978\n",
       "Negative emotion                       570\n",
       "I can't tell                           156\n",
       "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: int64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9093, 3)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_text                                               1\n",
       "emotion_in_tweet_is_directed_at                       5802\n",
       "is_there_an_emotion_directed_at_a_brand_or_product       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_df = df.drop('emotion_in_tweet_is_directed_at', axis=1)\n",
    "sent_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9093, 2)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df.drop(index=9092, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9091, 2)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df['sentiment'] = sent_df['is_there_an_emotion_directed_at_a_brand_or_product']\n",
    "sent_df.drop('is_there_an_emotion_directed_at_a_brand_or_product', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9087</th>\n",
       "      <td>@mention Yup, but I don't have a third app yet...</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your re...</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>Google's Zeiger, a physician never reported po...</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>Some Verizon iPhone customers complained their...</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9091 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  \\\n",
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3     @sxsw I hope this year's festival isn't as cra...   \n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "...                                                 ...   \n",
       "9087  @mention Yup, but I don't have a third app yet...   \n",
       "9088                      Ipad everywhere. #SXSW {link}   \n",
       "9089  Wave, buzz... RT @mention We interrupt your re...   \n",
       "9090  Google's Zeiger, a physician never reported po...   \n",
       "9091  Some Verizon iPhone customers complained their...   \n",
       "\n",
       "                               sentiment  \n",
       "0                       Negative emotion  \n",
       "1                       Positive emotion  \n",
       "2                       Positive emotion  \n",
       "3                       Negative emotion  \n",
       "4                       Positive emotion  \n",
       "...                                  ...  \n",
       "9087  No emotion toward brand or product  \n",
       "9088                    Positive emotion  \n",
       "9089  No emotion toward brand or product  \n",
       "9090  No emotion toward brand or product  \n",
       "9091  No emotion toward brand or product  \n",
       "\n",
       "[9091 rows x 2 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on I don't know not being useful for our predictive model and there only being 156 data points, \n",
    "# we decided to drop these rows\n",
    "sent_df.drop(sent_df.loc[sent_df['sentiment']==\"I can't tell\"].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8935, 2)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an intance of the RegexpTokenizer with the variable name `tokenizer`\n",
    "# The regex pattern should select all words with three or more characters\n",
    "tokenizer = RegexpTokenizer(pattern=r\"(?u)[\\w#]{3,}\")\n",
    "\n",
    "# Create a list of stopwords in English\n",
    "stopwords_list = stopwords.words('english')\n",
    "# Can add to stopwords_list here\n",
    "stopwords_list.extend(['#sxsw', 'mention', 'googl', 'link', 'ipad','quot', 'appl', 'iphon', 'store', 'circl'])\n",
    "stopwords_list.extend(['new','app','austin','like','launch','pop','sxsw', 'line', 'get', 'amp'])\n",
    "\n",
    "# Create an instance of nltk's PorterStemmer with the variable name `stemmer`\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " '#sxsw',\n",
       " 'mention',\n",
       " 'googl',\n",
       " 'link',\n",
       " 'ipad',\n",
       " 'quot',\n",
       " 'appl',\n",
       " 'iphon',\n",
       " 'store',\n",
       " 'circl',\n",
       " 'new',\n",
       " 'app',\n",
       " 'austin',\n",
       " 'like',\n",
       " 'launch',\n",
       " 'pop',\n",
       " 'sxsw',\n",
       " 'line',\n",
       " 'get',\n",
       " 'amp']"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CodeGrade step2\n",
    "def preprocess_text(text, tokenizer, stopwords_list, stemmer):\n",
    "    # Standardize case (lowercase the text)\n",
    "    text = text.lower()\n",
    "    # Tokenize text using `tokenizer`\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    # Remove stopwords using `stopwords_list`\n",
    "    filtered_text = [token for token in tokenized_text if token not in stopwords_list]\n",
    "    # Stem the tokenized text using `stemmer`\n",
    "    stemmed_text = [stemmer.stem(token) for token in filtered_text]\n",
    "    # Remove stopword stems using extended `stopwords_list`\n",
    "    stemmed_filtered_text = [token for token in stemmed_text if token not in stopwords_list]\n",
    "    # Return the preprocessed text (do not join, just return the list of tokens)\n",
    "    return stemmed_filtered_text\n",
    "# preprocess_text(\"This is an example sentence for preprocessing.\", tokenizer, stopwords_list, stemmer)\n",
    "# preprocess_text(sent_df['tweet_text'][2], tokenizer, stopwords_list, stemmer)\n",
    "sent_df['preprocessed_text'] = sent_df['tweet_text'].apply(lambda x: preprocess_text(x, tokenizer, stopwords_list, stemmer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>[wesley83, hr, tweet, #rise_austin, dead, need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[jessede, know, fludapp, awesom, appreci, desi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[swonderlin, wait, #ipad, also, sale]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>[hope, year, festiv, crashi, year]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[sxtxstate, great, stuff, fri, marissa, mayer,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9087</th>\n",
       "      <td>@mention Yup, but I don't have a third app yet...</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>[yup, third, yet, android, suggest]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[everywher]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your re...</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>[wave, buzz, interrupt, regularli, schedul, ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>Google's Zeiger, a physician never reported po...</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>[zeiger, physician, never, report, potenti, ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>Some Verizon iPhone customers complained their...</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>[verizon, custom, complain, time, fell, back, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8935 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  \\\n",
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3     @sxsw I hope this year's festival isn't as cra...   \n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "...                                                 ...   \n",
       "9087  @mention Yup, but I don't have a third app yet...   \n",
       "9088                      Ipad everywhere. #SXSW {link}   \n",
       "9089  Wave, buzz... RT @mention We interrupt your re...   \n",
       "9090  Google's Zeiger, a physician never reported po...   \n",
       "9091  Some Verizon iPhone customers complained their...   \n",
       "\n",
       "                               sentiment  \\\n",
       "0                       Negative emotion   \n",
       "1                       Positive emotion   \n",
       "2                       Positive emotion   \n",
       "3                       Negative emotion   \n",
       "4                       Positive emotion   \n",
       "...                                  ...   \n",
       "9087  No emotion toward brand or product   \n",
       "9088                    Positive emotion   \n",
       "9089  No emotion toward brand or product   \n",
       "9090  No emotion toward brand or product   \n",
       "9091  No emotion toward brand or product   \n",
       "\n",
       "                                      preprocessed_text  \n",
       "0     [wesley83, hr, tweet, #rise_austin, dead, need...  \n",
       "1     [jessede, know, fludapp, awesom, appreci, desi...  \n",
       "2                 [swonderlin, wait, #ipad, also, sale]  \n",
       "3                    [hope, year, festiv, crashi, year]  \n",
       "4     [sxtxstate, great, stuff, fri, marissa, mayer,...  \n",
       "...                                                 ...  \n",
       "9087                [yup, third, yet, android, suggest]  \n",
       "9088                                        [everywher]  \n",
       "9089  [wave, buzz, interrupt, regularli, schedul, ge...  \n",
       "9090  [zeiger, physician, never, report, potenti, ye...  \n",
       "9091  [verizon, custom, complain, time, fell, back, ...  \n",
       "\n",
       "[8935 rows x 3 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_df[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HOORAY RT \\x89ÛÏ@mention Apple Is Opening A Pop-Up Store In Austin For #SXSW | @mention {link}'"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet_text'][47]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       .@wesley83 I have a 3G iPhone. After 3 hrs twe...\n",
       "1       @jessedee Know about @fludapp ? Awesome iPad/i...\n",
       "2       @swonderlin Can not wait for #iPad 2 also. The...\n",
       "3       @sxsw I hope this year's festival isn't as cra...\n",
       "4       @sxtxstate great stuff on Fri #SXSW: Marissa M...\n",
       "                              ...                        \n",
       "9087    @mention Yup, but I don't have a third app yet...\n",
       "9088                        Ipad everywhere. #SXSW {link}\n",
       "9089    Wave, buzz... RT @mention We interrupt your re...\n",
       "9090    Google's Zeiger, a physician never reported po...\n",
       "9091    Some Verizon iPhone customers complained their...\n",
       "Name: tweet_text, Length: 8935, dtype: object"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_df['tweet_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up figure and axes\n",
    "fig, axes = plt.subplots(nrows=3, figsize=(12, 12))\n",
    "\n",
    "# Empty dict to hold words that have already been plotted and their colors\n",
    "plotted_words_and_colors = {}\n",
    "# Establish color palette to pull from\n",
    "# (If you get an error message about popping from an empty list, increase this #)\n",
    "color_palette = sns.color_palette('cividis', n_colors=38)\n",
    "\n",
    "# Creating a plot for each unique genre\n",
    "data_by_sent = [y for _, y in sent_df.groupby('sentiment', as_index=False)]\n",
    "for idx, group in enumerate(data_by_sent):\n",
    "    # Find top 10 words in this genre\n",
    "    all_words_in_sent = group.preprocessed_text.explode()\n",
    "    top_10 = all_words_in_sent.value_counts()[:10]\n",
    "    \n",
    "    # Select appropriate colors, reusing colors if words repeat\n",
    "    colors = []\n",
    "    for word in top_10.index:\n",
    "        if word not in plotted_words_and_colors:\n",
    "            new_color = color_palette.pop(0)\n",
    "            plotted_words_and_colors[word] = new_color\n",
    "        colors.append(plotted_words_and_colors[word])\n",
    "    \n",
    "    # Select axes, plot data, set title\n",
    "    ax = axes[idx]\n",
    "    ax.bar(top_10.index, top_10.values, color=colors)\n",
    "    ax.set_title(group.iloc[0].sentiment.title())\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    5387\n",
       "Positive emotion                      2978\n",
       "Negative emotion                       570\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3157                                  show uzu #tapworthi\n",
       "7553    seat turkey bowl armadillo kill list sxxpress ...\n",
       "7186      reason continu surviv exist god #enchant #sxswi\n",
       "7288    denni crowley competitor think start compet bi...\n",
       "628                              popup gee wonder traffic\n",
       "                              ...                        \n",
       "5593    cameron sinclair spearhead japan disast relief...\n",
       "7664                   #ipad therefor #appl near send pic\n",
       "6173               crazi look around realiz last year one\n",
       "987              nice outsid #appl guess peopl want ipad2\n",
       "8310                              might well popup #ipad2\n",
       "Name: joined_preprocessed_text, Length: 6701, dtype: object"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert token lists to strings\n",
    "sent_df[\"joined_preprocessed_text\"] = sent_df[\"preprocessed_text\"].str.join(\" \")\n",
    "\n",
    "# Create train test split\n",
    "X = sent_df['joined_preprocessed_text']\n",
    "y = sent_df['sentiment']\n",
    "# Explain zoom room 3 here\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=333)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_steps = [('cv', CountVectorizer(stop_words='english')),\n",
    "         ('tree', DecisionTreeClassifier())]\n",
    "\n",
    "tree_pipe = Pipeline(tree_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;cv&#x27;, CountVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;tree&#x27;, DecisionTreeClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;cv&#x27;, CountVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;tree&#x27;, DecisionTreeClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(stop_words=&#x27;english&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('cv', CountVectorizer(stop_words='english')),\n",
       "                ('tree', DecisionTreeClassifier())])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9579167288464409"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, ConfusionMatrixDisplay, recall_score, confusion_matrix\n",
    "y_pred = tree_pipe.predict(X_train)\n",
    "accuracy_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_steps = [('cv', CountVectorizer(stop_words='english')),\n",
    "         ('forest', RandomForestClassifier(random_state=333))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_pipe = Pipeline(forest_steps)\n",
    "forest_pipe.fit(X_train, y_train)\n",
    "y_pred = fortest_pipe.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.9579167288464409\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('train accuracy:', accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x21b45fe3b80>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf = confusion_matrix(y_train, y_pred)\n",
    "ConfusionMatrixDisplay(cf).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 = Negative Emotion, 1 = No Emotion, 2 = Positive Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'forest__max_depth': [10, 100, None],\n",
    "         'forest__max_features': [5, 50, 100, None],\n",
    "         'forest__n_estimators': [100, 500, 1000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_grid = GridSearchCV(estimator=forest_pipe, param_grid=params, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-214-a7380e777af7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mforest_grid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1149\u001b[0m                 )\n\u001b[0;32m   1150\u001b[0m             ):\n\u001b[1;32m-> 1151\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    896\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 898\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    899\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1417\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1418\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1419\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    843\u001b[0m                     )\n\u001b[0;32m    844\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 845\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    846\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    847\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         )\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1862\u001b[0m             \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1863\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1864\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1865\u001b[0m         \u001b[1;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1791\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1792\u001b[1;33m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1793\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1794\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    730\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 732\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    734\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1149\u001b[0m                 )\n\u001b[0;32m   1150\u001b[0m             ):\n\u001b[1;32m-> 1151\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    418\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"passthrough\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1149\u001b[0m                 )\n\u001b[0;32m   1150\u001b[0m             ):\n\u001b[1;32m-> 1151\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    454\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 456\u001b[1;33m             trees = Parallel(\n\u001b[0m\u001b[0;32m    457\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         )\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1862\u001b[0m             \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1863\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1864\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1865\u001b[0m         \u001b[1;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1791\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1792\u001b[1;33m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1793\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1794\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    186\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"balanced\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1149\u001b[0m                 )\n\u001b[0;32m   1150\u001b[0m             ):\n\u001b[1;32m-> 1151\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    957\u001b[0m         \"\"\"\n\u001b[0;32m    958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 959\u001b[1;33m         super()._fit(\n\u001b[0m\u001b[0;32m    960\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    961\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    441\u001b[0m             )\n\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing_values_in_feature_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "forest_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
