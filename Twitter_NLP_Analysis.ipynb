{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter NLP Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "A one-paragraph overview of the project, including the business problem, data, methods, results and recommendations.\n",
    "\n",
    "## Business Problem\n",
    "\n",
    "Summary of the business problem you are trying to solve, and the data questions that you plan to answer to solve them.\n",
    "\n",
    "Questions to consider:\n",
    "\n",
    "- Who are your stakeholders?\n",
    "- What are your stakeholders' pain points related to this project?\n",
    "- Why are your predictions important from a business perspective?\n",
    "- What exactly is your deliverable: your analysis, or the model itself?\n",
    "- Does your business understanding/stakeholder require a specific type of model?\n",
    "    - For example: a highly regulated industry would require a very transparent/simple/interpretable model, whereas a situation where the model itself is your deliverable would likely benefit from a more complex and thus stronger model\n",
    "   \n",
    "\n",
    "Additional questions to consider for classification:\n",
    "\n",
    "- What does a false positive look like in this context?\n",
    "- What does a false negative look like in this context?\n",
    "- Which is worse for your stakeholder?\n",
    "- What metric are you focusing on optimizing, given the answers to the above questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "\n",
    "The data comes from CrowdFlower via [data.world](https://data.world/crowdflower/brands-and-product-emotions). It consists of 9,000 tweets about Apple and Google products from a South by Southwest (SXSW) event. Human raters rated the sentiment of the tweets as positive, negative, neutral, or indistinguishable. There are 3 columns including the tweet, the product the tweet is about, and the sentiment of the tweet. The variable we used as the target is sentiment. Our goal is to find key words in tweets that can be used to identify the sentiment of each tweet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\42ben\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing everything we will need\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, ConfusionMatrixDisplay, recall_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in the data\n",
    "df = pd.read_csv(\"tweets.csv\", encoding='latin1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iPad                               946\n",
       "Apple                              661\n",
       "iPad or iPhone App                 470\n",
       "Google                             430\n",
       "iPhone                             297\n",
       "Other Google product or service    293\n",
       "Android App                         81\n",
       "Android                             78\n",
       "Other Apple product or service      35\n",
       "Name: emotion_in_tweet_is_directed_at, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['emotion_in_tweet_is_directed_at'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    5389\n",
       "Positive emotion                      2978\n",
       "Negative emotion                       570\n",
       "I can't tell                           156\n",
       "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9093, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_text                                               1\n",
       "emotion_in_tweet_is_directed_at                       5802\n",
       "is_there_an_emotion_directed_at_a_brand_or_product       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "The steps we took to prepare our data before NLP processing included:\n",
    " - dropping a column\n",
    " - dropping a null\n",
    " - renaming a column\n",
    " - dropping tweets with 'I can't tell' as sentiment\n",
    "\n",
    "The NLP steps performed included:\n",
    " - tokenizing\n",
    " - removing stopwords\n",
    " - stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropped `emotion_in_tweet_is_directed_at` column because we focused on the relationship between the `tweet_text` and the sentiment of the respective tweet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping middle column in DataFrame\n",
    "sent_df = df.drop('emotion_in_tweet_is_directed_at', axis=1)\n",
    "sent_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropped the one and only null row in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping nulls\n",
    "sent_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changed `is_there_an_emotion_directed_at_a_brand_or_product` to `sentiment` to make it more manageable and interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing name of column\n",
    "sent_df['sentiment'] = sent_df['is_there_an_emotion_directed_at_a_brand_or_product']\n",
    "sent_df.drop('is_there_an_emotion_directed_at_a_brand_or_product', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on \"I can't tell\" not being useful for our predictive model and there only being 156 corresponding data points, we decided to drop these rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df.drop(sent_df.loc[sent_df['sentiment']==\"I can't tell\"].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We included hashtags in our Regex pattern becuase we thought hashtags can add valuable meaning in order to predict sentiment. However, we did not include mentions because these do not seem to add valuable meaning when predicting sentiment. We began with the corpus of stopwords from nltk. We added to the list of stopwords later when looking at a chart in our notebook showing the top tokens from each category. This will be explained more in depth later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an intance of the RegexpTokenizer with the variable name `tokenizer`\n",
    "# The regex pattern should select all words with three or more characters\n",
    "tokenizer = RegexpTokenizer(pattern=r\"(?u)[\\w#]{3,}\")\n",
    "\n",
    "# Create a list of stopwords in English\n",
    "stopwords_list = stopwords.words('english')\n",
    "# Add to stopwords_list here\n",
    "stopwords_list.extend(['#sxsw', 'mention', 'googl', 'link', 'ipad','quot', 'appl', 'iphon', 'store', 'circl'])\n",
    "stopwords_list.extend(['new','app','austin','like','launch','pop','sxsw', 'line', 'get', 'amp'])\n",
    "\n",
    "# Create an instance of nltk's PorterStemmer with the variable name `stemmer`\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created a function that preproccesses the tweets by standardizing, tokenizing, removing stopwords, stemming, and removing tokens we decided to exclude after looking at the chart below. These were removed because they appeared commonly among all sentiments. These tokens had already been stemmed, this is why we remove stopwords again after the stemming in this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, tokenizer, stopwords_list, stemmer):\n",
    "    # Standardize case (lowercase the text)\n",
    "    text = text.lower()\n",
    "    # Tokenize text using `tokenizer`\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    # Remove stopwords using `stopwords_list`\n",
    "    filtered_text = [token for token in tokenized_text if token not in stopwords_list]\n",
    "    # Stem the tokenized text using `stemmer`\n",
    "    stemmed_text = [stemmer.stem(token) for token in filtered_text]\n",
    "    # Remove stopword stems using extended `stopwords_list`\n",
    "    stemmed_filtered_text = [token for token in stemmed_text if token not in stopwords_list]\n",
    "    # Return the preprocessed text (do not join, just return the list of tokens)\n",
    "    return stemmed_filtered_text\n",
    "# Apply function to 'tweet_text' column\n",
    "sent_df['preprocessed_text'] = sent_df['tweet_text'].apply(lambda x: preprocess_text(x, tokenizer, stopwords_list, stemmer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created three bar charts that display the top 10 most common tokens in each sentiment group (positive, negative, and neutral). These charts are how we decided which tokens needed to be added to our stopwords list. If a token was prevelant in all sentiment groups we added it to our stopwords list because these tokens do not add any value in determining sentiment. This process was repeated until we felt the top tokens were diverse and meaningful.\n",
    "\n",
    "Paying attention to the class imbalance is important for this process. For example, in this final iteration of the charts 'social' appears as a top token in the neutral and negative groups. The scales between these groups is substantial: 'social' appears about 30 times in the negative group and nearly 500 times in the neutral group. Due to this difference we decided not to add 'social' to our stopwords list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up figure and axes\n",
    "fig, axes = plt.subplots(nrows=3, figsize=(12, 12))\n",
    "\n",
    "# Empty dict to hold words that have already been plotted and their colors\n",
    "plotted_words_and_colors = {}\n",
    "# Establish color palette to pull from\n",
    "color_palette = sns.color_palette('cividis', n_colors=38)\n",
    "\n",
    "# Create a plot for each unique sentiment\n",
    "data_by_sent = [y for _, y in sent_df.groupby('sentiment', as_index=False)]\n",
    "for idx, group in enumerate(data_by_sent):\n",
    "    # Find top 10 words in each sentiment\n",
    "    all_words_in_sent = group.preprocessed_text.explode()\n",
    "    top_10 = all_words_in_sent.value_counts()[:10]\n",
    "    \n",
    "    # Select appropriate colors, reusing colors if words repeat\n",
    "    colors = []\n",
    "    for word in top_10.index:\n",
    "        if word not in plotted_words_and_colors:\n",
    "            new_color = color_palette.pop(0)\n",
    "            plotted_words_and_colors[word] = new_color\n",
    "        colors.append(plotted_words_and_colors[word])\n",
    "    \n",
    "    # Select axes, plot data, set title\n",
    "    ax = axes[idx]\n",
    "    ax.bar(top_10.index, top_10.values, color=colors)\n",
    "    ax.set_title(group.iloc[0].sentiment.title())\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all the actions above were completed, the data was ready for a train/test split in order to begin the modeling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7817    everyon alreadi one anti theft protect leav la...\n",
       "3158                             kick talk design headach\n",
       "7555    frabjou day callooh callay baaah lewi carrol...\n",
       "6829            umm would keep win shit thank killer case\n",
       "3719                    design interfac navig schema #uxd\n",
       "                              ...                        \n",
       "5593    cameron sinclair spearhead japan disast relief...\n",
       "7664                   #ipad therefor #appl near send pic\n",
       "6173               crazi look around realiz last year one\n",
       "987              nice outsid #appl guess peopl want ipad2\n",
       "8310                              might well popup #ipad2\n",
       "Name: joined_preprocessed_text, Length: 6702, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert token lists to strings\n",
    "sent_df[\"joined_preprocessed_text\"] = sent_df[\"preprocessed_text\"].str.join(\" \")\n",
    "\n",
    "# Create train test split\n",
    "X = sent_df['joined_preprocessed_text']\n",
    "y = sent_df['sentiment']\n",
    "# Explain zoom room 3 here\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=333)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "Describe and justify the process for analyzing or modeling the data.\n",
    "\n",
    "Questions to consider:\n",
    "\n",
    "- How will you analyze the data to arrive at an initial approach?\n",
    "- How will you iterate on your initial approach to make it better?\n",
    "- What model type is most appropriate, given the data and the business problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "The evaluation of each model should accompany the creation of each model, and you should be sure to evaluate your models consistently.\n",
    "\n",
    "Evaluate how well your work solves the stated business problem. \n",
    "\n",
    "Questions to consider:\n",
    "\n",
    "- How do you interpret the results?\n",
    "- How well does your model fit your data? How much better is this than your baseline model? Is it over or under fit?\n",
    "- How well does your model/data fit any relevant modeling assumptions?\n",
    "\n",
    "For the final model, you might also consider:\n",
    "\n",
    "- How confident are you that your results would generalize beyond the data you have?\n",
    "- How confident are you that this model would benefit the business if put into use?\n",
    "- What does this final model tell you about the relationship between your inputs and outputs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Understanding\n",
    "\n",
    "The most dominant sentiment in the data is neutral, therefore we set our baseline accuracy as a model predicting neutral sentiment every time. This would result in an accuracy score of approximately 60%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6029543419874664"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting baseline_accuracy equal to the normalized value_counts of neutral sentiment\n",
    "baseline_accuracy = sent_df['sentiment'].value_counts(normalize=True)[0]\n",
    "baseline_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Model (Decision Tree)\n",
    "\n",
    "Created a decision tree model with all default parameters. Our goal here was to purposefully create an overfit model in order to confirm it achieves a high accuracy score. Accomplishing this tells us we are using good enough data in order to predict our targe variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;cv&#x27;, CountVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;tree&#x27;, DecisionTreeClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;cv&#x27;, CountVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;tree&#x27;, DecisionTreeClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(stop_words=&#x27;english&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('cv', CountVectorizer(stop_words='english')),\n",
       "                ('tree', DecisionTreeClassifier())])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating steps for a Pipeline \n",
    "tree_steps = [('cv', CountVectorizer(stop_words='english')),\n",
    "         ('tree', DecisionTreeClassifier())]\n",
    "# Feeding the Pipeline the steps defined above\n",
    "tree_pipe = Pipeline(tree_steps)\n",
    "# Fitting the training data to the Pipeline\n",
    "tree_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This worked successfully, this model received an accuracy score of 95.17% on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9571769621008654"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the predictions from the Pipeline using the training data\n",
    "y_pred = tree_pipe.predict(X_train)\n",
    "# Evaluating the accuracy score on the training data\n",
    "accuracy_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, the cross_val_score is much lower (64%) showing this model is very overfit. This is still performing a little better than the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.649508386479237"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating mean of the 5-fold cross_val_score\n",
    "cross_val_score(tree_pipe, X_train, y_train, cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Model (Random Forest)\n",
    "\n",
    "Created a Random Forest model with default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;cv&#x27;, CountVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;forest&#x27;, RandomForestClassifier(random_state=333))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;cv&#x27;, CountVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;forest&#x27;, RandomForestClassifier(random_state=333))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(stop_words=&#x27;english&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=333)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('cv', CountVectorizer(stop_words='english')),\n",
       "                ('forest', RandomForestClassifier(random_state=333))])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating steps for a Pipeline \n",
    "forest_steps = [('cv', CountVectorizer(stop_words='english')),\n",
    "         ('forest', RandomForestClassifier(random_state=333))]\n",
    "# Feeding the Pipeline the steps defined above\n",
    "forest_pipe = Pipeline(forest_steps)\n",
    "# Fitting the training data to the Pipeline\n",
    "forest_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this random forest model earned a high accuracy score on the training data but it is most likely due to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9571769621008654"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the predictions from the Pipeline using the training data\n",
    "y_pred = forest_pipe.predict(X_train)\n",
    "# Evaluating the accuracy score on the training data\n",
    "accuracy_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation score is a bit higher than it was for the decision tree model. This random forest model is still very overfit to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6809913519650073"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating mean of the 5-fold cross_val_score\n",
    "cross_val_score(forest_pipe, X_train, y_train, cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with GridSearch\n",
    "\n",
    "In order to combat the overfit results we used a GridSearch to help tune the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;cv&#x27;,\n",
       "                                        CountVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                                       (&#x27;forest&#x27;,\n",
       "                                        RandomForestClassifier(random_state=333))]),\n",
       "             param_grid={&#x27;forest__max_depth&#x27;: [10, 100, None],\n",
       "                         &#x27;forest__max_features&#x27;: [5, 50],\n",
       "                         &#x27;forest__n_estimators&#x27;: [5, 10]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;cv&#x27;,\n",
       "                                        CountVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                                       (&#x27;forest&#x27;,\n",
       "                                        RandomForestClassifier(random_state=333))]),\n",
       "             param_grid={&#x27;forest__max_depth&#x27;: [10, 100, None],\n",
       "                         &#x27;forest__max_features&#x27;: [5, 50],\n",
       "                         &#x27;forest__n_estimators&#x27;: [5, 10]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;cv&#x27;, CountVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;forest&#x27;, RandomForestClassifier(random_state=333))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(stop_words=&#x27;english&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=333)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cv',\n",
       "                                        CountVectorizer(stop_words='english')),\n",
       "                                       ('forest',\n",
       "                                        RandomForestClassifier(random_state=333))]),\n",
       "             param_grid={'forest__max_depth': [10, 100, None],\n",
       "                         'forest__max_features': [5, 50],\n",
       "                         'forest__n_estimators': [5, 10]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating parameters for GridSearch\n",
    "params = {'forest__max_depth': [10, 100, None],\n",
    "         'forest__max_features': [5, 50],\n",
    "         'forest__n_estimators': [5, 10]}\n",
    "# GridSearch with the random forest pipeline, parameters above, 5 fold cross validation, and accuracy score\n",
    "forest_grid = GridSearchCV(estimator=forest_pipe, param_grid=params, cv=5, scoring='accuracy')\n",
    "# Fitting the GridSearch\n",
    "forest_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GridSearch discovered max_depth=None, max_features=5, and n_estimators=10 had the best cross validation score. This is a worse score than the random forest model with default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('cv', CountVectorizer(stop_words='english')),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(max_features=5, n_estimators=10,\n",
      "                                        random_state=333))])\n",
      "0.667711331485748\n"
     ]
    }
   ],
   "source": [
    "# Displaying the best estimator from the GridSearch and the accuracy score\n",
    "print(forest_grid.best_estimator_)\n",
    "print(forest_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updated Params (1st time)\n",
    "\n",
    "Tried to improve results with new GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "[CV 1/5] END forest__max_depth=100, forest__max_features=50, forest__n_estimators=10;, score=0.654 total time=   1.6s\n",
      "[CV 2/5] END forest__max_depth=100, forest__max_features=50, forest__n_estimators=10;, score=0.657 total time=   1.5s\n",
      "[CV 3/5] END forest__max_depth=100, forest__max_features=50, forest__n_estimators=10;, score=0.661 total time=   1.5s\n",
      "[CV 4/5] END forest__max_depth=100, forest__max_features=50, forest__n_estimators=10;, score=0.682 total time=   1.5s\n",
      "[CV 5/5] END forest__max_depth=100, forest__max_features=50, forest__n_estimators=10;, score=0.663 total time=   1.5s\n",
      "[CV 1/5] END forest__max_depth=100, forest__max_features=50, forest__n_estimators=20;, score=0.677 total time=   3.3s\n",
      "[CV 2/5] END forest__max_depth=100, forest__max_features=50, forest__n_estimators=20;, score=0.671 total time=   3.0s\n",
      "[CV 3/5] END forest__max_depth=100, forest__max_features=50, forest__n_estimators=20;, score=0.672 total time=   3.0s\n",
      "[CV 4/5] END forest__max_depth=100, forest__max_features=50, forest__n_estimators=20;, score=0.687 total time=   3.1s\n",
      "[CV 5/5] END forest__max_depth=100, forest__max_features=50, forest__n_estimators=20;, score=0.676 total time=   3.2s\n",
      "[CV 1/5] END forest__max_depth=100, forest__max_features=50, forest__n_estimators=30;, score=0.680 total time=   4.9s\n",
      "[CV 2/5] END forest__max_depth=100, forest__max_features=50, forest__n_estimators=30;, score=0.673 total time=   4.8s\n",
      "[CV 3/5] END forest__max_depth=100, forest__max_features=50, forest__n_estimators=30;, score=0.670 total time=   4.5s\n",
      "[CV 4/5] END forest__max_depth=100, forest__max_features=50, forest__n_estimators=30;, score=0.688 total time=   4.8s\n",
      "[CV 5/5] END forest__max_depth=100, forest__max_features=50, forest__n_estimators=30;, score=0.684 total time=   4.7s\n",
      "[CV 1/5] END forest__max_depth=100, forest__max_features=75, forest__n_estimators=10;, score=0.666 total time=   1.6s\n",
      "[CV 2/5] END forest__max_depth=100, forest__max_features=75, forest__n_estimators=10;, score=0.685 total time=   1.6s\n",
      "[CV 3/5] END forest__max_depth=100, forest__max_features=75, forest__n_estimators=10;, score=0.672 total time=   1.6s\n",
      "[CV 4/5] END forest__max_depth=100, forest__max_features=75, forest__n_estimators=10;, score=0.660 total time=   1.7s\n",
      "[CV 5/5] END forest__max_depth=100, forest__max_features=75, forest__n_estimators=10;, score=0.669 total time=   1.5s\n",
      "[CV 1/5] END forest__max_depth=100, forest__max_features=75, forest__n_estimators=20;, score=0.678 total time=   3.3s\n",
      "[CV 2/5] END forest__max_depth=100, forest__max_features=75, forest__n_estimators=20;, score=0.694 total time=   3.2s\n",
      "[CV 3/5] END forest__max_depth=100, forest__max_features=75, forest__n_estimators=20;, score=0.669 total time=   3.1s\n",
      "[CV 4/5] END forest__max_depth=100, forest__max_features=75, forest__n_estimators=20;, score=0.675 total time=   3.3s\n",
      "[CV 5/5] END forest__max_depth=100, forest__max_features=75, forest__n_estimators=20;, score=0.675 total time=   3.1s\n",
      "[CV 1/5] END forest__max_depth=100, forest__max_features=75, forest__n_estimators=30;, score=0.679 total time=   5.1s\n",
      "[CV 2/5] END forest__max_depth=100, forest__max_features=75, forest__n_estimators=30;, score=0.685 total time=   4.8s\n",
      "[CV 3/5] END forest__max_depth=100, forest__max_features=75, forest__n_estimators=30;, score=0.669 total time=   4.7s\n",
      "[CV 4/5] END forest__max_depth=100, forest__max_features=75, forest__n_estimators=30;, score=0.679 total time=   5.0s\n",
      "[CV 5/5] END forest__max_depth=100, forest__max_features=75, forest__n_estimators=30;, score=0.676 total time=   4.8s\n",
      "[CV 1/5] END forest__max_depth=100, forest__max_features=100, forest__n_estimators=10;, score=0.668 total time=   1.6s\n",
      "[CV 2/5] END forest__max_depth=100, forest__max_features=100, forest__n_estimators=10;, score=0.694 total time=   1.5s\n",
      "[CV 3/5] END forest__max_depth=100, forest__max_features=100, forest__n_estimators=10;, score=0.666 total time=   1.7s\n",
      "[CV 4/5] END forest__max_depth=100, forest__max_features=100, forest__n_estimators=10;, score=0.681 total time=   1.6s\n",
      "[CV 5/5] END forest__max_depth=100, forest__max_features=100, forest__n_estimators=10;, score=0.675 total time=   1.5s\n",
      "[CV 1/5] END forest__max_depth=100, forest__max_features=100, forest__n_estimators=20;, score=0.676 total time=   3.3s\n",
      "[CV 2/5] END forest__max_depth=100, forest__max_features=100, forest__n_estimators=20;, score=0.679 total time=   3.2s\n",
      "[CV 3/5] END forest__max_depth=100, forest__max_features=100, forest__n_estimators=20;, score=0.661 total time=   3.5s\n",
      "[CV 4/5] END forest__max_depth=100, forest__max_features=100, forest__n_estimators=20;, score=0.687 total time=   3.4s\n",
      "[CV 5/5] END forest__max_depth=100, forest__max_features=100, forest__n_estimators=20;, score=0.678 total time=   3.2s\n",
      "[CV 1/5] END forest__max_depth=100, forest__max_features=100, forest__n_estimators=30;, score=0.674 total time=   5.1s\n",
      "[CV 2/5] END forest__max_depth=100, forest__max_features=100, forest__n_estimators=30;, score=0.690 total time=   4.9s\n",
      "[CV 3/5] END forest__max_depth=100, forest__max_features=100, forest__n_estimators=30;, score=0.661 total time=   5.0s\n",
      "[CV 4/5] END forest__max_depth=100, forest__max_features=100, forest__n_estimators=30;, score=0.690 total time=   5.1s\n",
      "[CV 5/5] END forest__max_depth=100, forest__max_features=100, forest__n_estimators=30;, score=0.684 total time=   4.8s\n",
      "[CV 1/5] END forest__max_depth=300, forest__max_features=50, forest__n_estimators=10;, score=0.664 total time=   2.9s\n",
      "[CV 2/5] END forest__max_depth=300, forest__max_features=50, forest__n_estimators=10;, score=0.685 total time=   2.9s\n",
      "[CV 3/5] END forest__max_depth=300, forest__max_features=50, forest__n_estimators=10;, score=0.658 total time=   2.8s\n",
      "[CV 4/5] END forest__max_depth=300, forest__max_features=50, forest__n_estimators=10;, score=0.679 total time=   2.8s\n",
      "[CV 5/5] END forest__max_depth=300, forest__max_features=50, forest__n_estimators=10;, score=0.672 total time=   2.8s\n",
      "[CV 1/5] END forest__max_depth=300, forest__max_features=50, forest__n_estimators=20;, score=0.670 total time=   5.9s\n",
      "[CV 2/5] END forest__max_depth=300, forest__max_features=50, forest__n_estimators=20;, score=0.688 total time=   6.0s\n",
      "[CV 3/5] END forest__max_depth=300, forest__max_features=50, forest__n_estimators=20;, score=0.676 total time=   5.7s\n",
      "[CV 4/5] END forest__max_depth=300, forest__max_features=50, forest__n_estimators=20;, score=0.688 total time=   5.8s\n",
      "[CV 5/5] END forest__max_depth=300, forest__max_features=50, forest__n_estimators=20;, score=0.696 total time=   5.6s\n",
      "[CV 1/5] END forest__max_depth=300, forest__max_features=50, forest__n_estimators=30;, score=0.670 total time=   8.9s\n",
      "[CV 2/5] END forest__max_depth=300, forest__max_features=50, forest__n_estimators=30;, score=0.693 total time=   8.9s\n",
      "[CV 3/5] END forest__max_depth=300, forest__max_features=50, forest__n_estimators=30;, score=0.681 total time=   8.4s\n",
      "[CV 4/5] END forest__max_depth=300, forest__max_features=50, forest__n_estimators=30;, score=0.687 total time=   9.0s\n",
      "[CV 5/5] END forest__max_depth=300, forest__max_features=50, forest__n_estimators=30;, score=0.690 total time=   8.7s\n",
      "[CV 1/5] END forest__max_depth=300, forest__max_features=75, forest__n_estimators=10;, score=0.663 total time=   2.8s\n",
      "[CV 2/5] END forest__max_depth=300, forest__max_features=75, forest__n_estimators=10;, score=0.691 total time=   2.8s\n",
      "[CV 3/5] END forest__max_depth=300, forest__max_features=75, forest__n_estimators=10;, score=0.672 total time=   2.7s\n",
      "[CV 4/5] END forest__max_depth=300, forest__max_features=75, forest__n_estimators=10;, score=0.678 total time=   2.9s\n",
      "[CV 5/5] END forest__max_depth=300, forest__max_features=75, forest__n_estimators=10;, score=0.681 total time=   2.7s\n",
      "[CV 1/5] END forest__max_depth=300, forest__max_features=75, forest__n_estimators=20;, score=0.671 total time=   5.8s\n",
      "[CV 2/5] END forest__max_depth=300, forest__max_features=75, forest__n_estimators=20;, score=0.699 total time=   5.6s\n",
      "[CV 3/5] END forest__max_depth=300, forest__max_features=75, forest__n_estimators=20;, score=0.672 total time=   5.5s\n",
      "[CV 4/5] END forest__max_depth=300, forest__max_features=75, forest__n_estimators=20;, score=0.691 total time=   5.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END forest__max_depth=300, forest__max_features=75, forest__n_estimators=20;, score=0.690 total time=   5.5s\n",
      "[CV 1/5] END forest__max_depth=300, forest__max_features=75, forest__n_estimators=30;, score=0.671 total time=   8.5s\n",
      "[CV 2/5] END forest__max_depth=300, forest__max_features=75, forest__n_estimators=30;, score=0.698 total time=   8.6s\n",
      "[CV 3/5] END forest__max_depth=300, forest__max_features=75, forest__n_estimators=30;, score=0.669 total time=   8.1s\n",
      "[CV 4/5] END forest__max_depth=300, forest__max_features=75, forest__n_estimators=30;, score=0.685 total time=   8.7s\n",
      "[CV 5/5] END forest__max_depth=300, forest__max_features=75, forest__n_estimators=30;, score=0.687 total time=   8.4s\n",
      "[CV 1/5] END forest__max_depth=300, forest__max_features=100, forest__n_estimators=10;, score=0.670 total time=   2.7s\n",
      "[CV 2/5] END forest__max_depth=300, forest__max_features=100, forest__n_estimators=10;, score=0.678 total time=   2.6s\n",
      "[CV 3/5] END forest__max_depth=300, forest__max_features=100, forest__n_estimators=10;, score=0.674 total time=   2.8s\n",
      "[CV 4/5] END forest__max_depth=300, forest__max_features=100, forest__n_estimators=10;, score=0.676 total time=   2.7s\n",
      "[CV 5/5] END forest__max_depth=300, forest__max_features=100, forest__n_estimators=10;, score=0.687 total time=   2.6s\n",
      "[CV 1/5] END forest__max_depth=300, forest__max_features=100, forest__n_estimators=20;, score=0.673 total time=   5.6s\n",
      "[CV 2/5] END forest__max_depth=300, forest__max_features=100, forest__n_estimators=20;, score=0.680 total time=   5.6s\n",
      "[CV 3/5] END forest__max_depth=300, forest__max_features=100, forest__n_estimators=20;, score=0.679 total time=   5.6s\n",
      "[CV 4/5] END forest__max_depth=300, forest__max_features=100, forest__n_estimators=20;, score=0.683 total time=   5.5s\n",
      "[CV 5/5] END forest__max_depth=300, forest__max_features=100, forest__n_estimators=20;, score=0.689 total time=   5.4s\n",
      "[CV 1/5] END forest__max_depth=300, forest__max_features=100, forest__n_estimators=30;, score=0.669 total time=   8.4s\n",
      "[CV 2/5] END forest__max_depth=300, forest__max_features=100, forest__n_estimators=30;, score=0.686 total time=   8.4s\n",
      "[CV 3/5] END forest__max_depth=300, forest__max_features=100, forest__n_estimators=30;, score=0.676 total time=   8.2s\n",
      "[CV 4/5] END forest__max_depth=300, forest__max_features=100, forest__n_estimators=30;, score=0.694 total time=   8.3s\n",
      "[CV 5/5] END forest__max_depth=300, forest__max_features=100, forest__n_estimators=30;, score=0.689 total time=   8.2s\n",
      "[CV 1/5] END forest__max_depth=None, forest__max_features=50, forest__n_estimators=10;, score=0.670 total time=   3.8s\n",
      "[CV 2/5] END forest__max_depth=None, forest__max_features=50, forest__n_estimators=10;, score=0.673 total time=   3.9s\n",
      "[CV 3/5] END forest__max_depth=None, forest__max_features=50, forest__n_estimators=10;, score=0.651 total time=   3.7s\n",
      "[CV 4/5] END forest__max_depth=None, forest__max_features=50, forest__n_estimators=10;, score=0.669 total time=   3.8s\n",
      "[CV 5/5] END forest__max_depth=None, forest__max_features=50, forest__n_estimators=10;, score=0.674 total time=   3.7s\n",
      "[CV 1/5] END forest__max_depth=None, forest__max_features=50, forest__n_estimators=20;, score=0.658 total time=   7.7s\n",
      "[CV 2/5] END forest__max_depth=None, forest__max_features=50, forest__n_estimators=20;, score=0.680 total time=   7.7s\n",
      "[CV 3/5] END forest__max_depth=None, forest__max_features=50, forest__n_estimators=20;, score=0.666 total time=   7.5s\n",
      "[CV 4/5] END forest__max_depth=None, forest__max_features=50, forest__n_estimators=20;, score=0.681 total time=   7.7s\n",
      "[CV 5/5] END forest__max_depth=None, forest__max_features=50, forest__n_estimators=20;, score=0.686 total time=   7.6s\n",
      "[CV 1/5] END forest__max_depth=None, forest__max_features=50, forest__n_estimators=30;, score=0.673 total time=  11.5s\n",
      "[CV 2/5] END forest__max_depth=None, forest__max_features=50, forest__n_estimators=30;, score=0.685 total time=  11.8s\n",
      "[CV 3/5] END forest__max_depth=None, forest__max_features=50, forest__n_estimators=30;, score=0.659 total time=  11.2s\n",
      "[CV 4/5] END forest__max_depth=None, forest__max_features=50, forest__n_estimators=30;, score=0.690 total time=  11.6s\n",
      "[CV 5/5] END forest__max_depth=None, forest__max_features=50, forest__n_estimators=30;, score=0.684 total time=  11.5s\n",
      "[CV 1/5] END forest__max_depth=None, forest__max_features=75, forest__n_estimators=10;, score=0.658 total time=   3.6s\n",
      "[CV 2/5] END forest__max_depth=None, forest__max_features=75, forest__n_estimators=10;, score=0.674 total time=   3.6s\n",
      "[CV 3/5] END forest__max_depth=None, forest__max_features=75, forest__n_estimators=10;, score=0.670 total time=   3.7s\n",
      "[CV 4/5] END forest__max_depth=None, forest__max_features=75, forest__n_estimators=10;, score=0.684 total time=   3.7s\n",
      "[CV 5/5] END forest__max_depth=None, forest__max_features=75, forest__n_estimators=10;, score=0.667 total time=   3.7s\n",
      "[CV 1/5] END forest__max_depth=None, forest__max_features=75, forest__n_estimators=20;, score=0.669 total time=   7.3s\n",
      "[CV 2/5] END forest__max_depth=None, forest__max_features=75, forest__n_estimators=20;, score=0.681 total time=   7.4s\n",
      "[CV 3/5] END forest__max_depth=None, forest__max_features=75, forest__n_estimators=20;, score=0.675 total time=   7.3s\n",
      "[CV 4/5] END forest__max_depth=None, forest__max_features=75, forest__n_estimators=20;, score=0.684 total time=   7.6s\n",
      "[CV 5/5] END forest__max_depth=None, forest__max_features=75, forest__n_estimators=20;, score=0.679 total time=   7.3s\n",
      "[CV 1/5] END forest__max_depth=None, forest__max_features=75, forest__n_estimators=30;, score=0.667 total time=  11.0s\n",
      "[CV 2/5] END forest__max_depth=None, forest__max_features=75, forest__n_estimators=30;, score=0.683 total time=  11.3s\n",
      "[CV 3/5] END forest__max_depth=None, forest__max_features=75, forest__n_estimators=30;, score=0.674 total time=  11.0s\n",
      "[CV 4/5] END forest__max_depth=None, forest__max_features=75, forest__n_estimators=30;, score=0.689 total time=  11.2s\n",
      "[CV 5/5] END forest__max_depth=None, forest__max_features=75, forest__n_estimators=30;, score=0.682 total time=  11.0s\n",
      "[CV 1/5] END forest__max_depth=None, forest__max_features=100, forest__n_estimators=10;, score=0.668 total time=   3.6s\n",
      "[CV 2/5] END forest__max_depth=None, forest__max_features=100, forest__n_estimators=10;, score=0.679 total time=   3.6s\n",
      "[CV 3/5] END forest__max_depth=None, forest__max_features=100, forest__n_estimators=10;, score=0.669 total time=   3.6s\n",
      "[CV 4/5] END forest__max_depth=None, forest__max_features=100, forest__n_estimators=10;, score=0.664 total time=   3.6s\n",
      "[CV 5/5] END forest__max_depth=None, forest__max_features=100, forest__n_estimators=10;, score=0.672 total time=   3.6s\n",
      "[CV 1/5] END forest__max_depth=None, forest__max_features=100, forest__n_estimators=20;, score=0.672 total time=   7.2s\n",
      "[CV 2/5] END forest__max_depth=None, forest__max_features=100, forest__n_estimators=20;, score=0.679 total time=   7.3s\n",
      "[CV 3/5] END forest__max_depth=None, forest__max_features=100, forest__n_estimators=20;, score=0.663 total time=   7.1s\n",
      "[CV 4/5] END forest__max_depth=None, forest__max_features=100, forest__n_estimators=20;, score=0.680 total time=   7.2s\n",
      "[CV 5/5] END forest__max_depth=None, forest__max_features=100, forest__n_estimators=20;, score=0.675 total time=   7.3s\n",
      "[CV 1/5] END forest__max_depth=None, forest__max_features=100, forest__n_estimators=30;, score=0.670 total time=  10.8s\n",
      "[CV 2/5] END forest__max_depth=None, forest__max_features=100, forest__n_estimators=30;, score=0.679 total time=  11.0s\n",
      "[CV 3/5] END forest__max_depth=None, forest__max_features=100, forest__n_estimators=30;, score=0.669 total time=  10.6s\n",
      "[CV 4/5] END forest__max_depth=None, forest__max_features=100, forest__n_estimators=30;, score=0.680 total time=  10.9s\n",
      "[CV 5/5] END forest__max_depth=None, forest__max_features=100, forest__n_estimators=30;, score=0.681 total time=  10.9s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;cv&#x27;,\n",
       "                                        CountVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                                       (&#x27;forest&#x27;,\n",
       "                                        RandomForestClassifier(random_state=333))]),\n",
       "             param_grid={&#x27;forest__max_depth&#x27;: [100, 300, None],\n",
       "                         &#x27;forest__max_features&#x27;: [50, 75, 100],\n",
       "                         &#x27;forest__n_estimators&#x27;: [10, 20, 30]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;cv&#x27;,\n",
       "                                        CountVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                                       (&#x27;forest&#x27;,\n",
       "                                        RandomForestClassifier(random_state=333))]),\n",
       "             param_grid={&#x27;forest__max_depth&#x27;: [100, 300, None],\n",
       "                         &#x27;forest__max_features&#x27;: [50, 75, 100],\n",
       "                         &#x27;forest__n_estimators&#x27;: [10, 20, 30]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;cv&#x27;, CountVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;forest&#x27;, RandomForestClassifier(random_state=333))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(stop_words=&#x27;english&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=333)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cv',\n",
       "                                        CountVectorizer(stop_words='english')),\n",
       "                                       ('forest',\n",
       "                                        RandomForestClassifier(random_state=333))]),\n",
       "             param_grid={'forest__max_depth': [100, 300, None],\n",
       "                         'forest__max_features': [50, 75, 100],\n",
       "                         'forest__n_estimators': [10, 20, 30]},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating parameters for GridSearch\n",
    "params2 = {'forest__max_depth': [100, 300, None],\n",
    "         'forest__max_features': [50, 75, 100],\n",
    "         'forest__n_estimators': [10, 20, 30]}\n",
    "# GridSearch with the random forest pipeline, parameters above, 5 fold cross validation, and accuracy score\n",
    "forest_grid2 = GridSearchCV(estimator=forest_pipe, param_grid=params2, cv=5, scoring='accuracy', verbose=3)\n",
    "# Fitting the GridSearch\n",
    "forest_grid2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GridSearch discovered max_depth=300, max_features=75, and n_estimators=20 had the best cross validation score. This is right around the same score as the random forest model with default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('cv', CountVectorizer(stop_words='english')),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(max_depth=300, max_features=75,\n",
      "                                        n_estimators=20, random_state=333))])\n",
      "0.6845715494117777\n"
     ]
    }
   ],
   "source": [
    "# Displaying the best estimator from the GridSearch and the accuracy score\n",
    "print(forest_grid2.best_estimator_)\n",
    "print(forest_grid2.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updated Params (2nd time)\n",
    "\n",
    "Tried to improve results with new GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "[CV] END forest__max_depth=300, forest__max_features=60, forest__n_estimators=30; total time=   8.5s\n",
      "[CV] END forest__max_depth=300, forest__max_features=60, forest__n_estimators=30; total time=   8.5s\n",
      "[CV] END forest__max_depth=300, forest__max_features=60, forest__n_estimators=30; total time=   8.4s\n",
      "[CV] END forest__max_depth=300, forest__max_features=60, forest__n_estimators=30; total time=   8.8s\n",
      "[CV] END forest__max_depth=300, forest__max_features=60, forest__n_estimators=30; total time=   8.5s\n",
      "[CV] END forest__max_depth=300, forest__max_features=60, forest__n_estimators=50; total time=  14.5s\n",
      "[CV] END forest__max_depth=300, forest__max_features=60, forest__n_estimators=50; total time=  14.5s\n",
      "[CV] END forest__max_depth=300, forest__max_features=60, forest__n_estimators=50; total time=  14.2s\n",
      "[CV] END forest__max_depth=300, forest__max_features=60, forest__n_estimators=50; total time=  14.6s\n",
      "[CV] END forest__max_depth=300, forest__max_features=60, forest__n_estimators=50; total time=  14.1s\n",
      "[CV] END forest__max_depth=300, forest__max_features=60, forest__n_estimators=70; total time=  20.2s\n",
      "[CV] END forest__max_depth=300, forest__max_features=60, forest__n_estimators=70; total time=  20.8s\n",
      "[CV] END forest__max_depth=300, forest__max_features=60, forest__n_estimators=70; total time=  19.8s\n",
      "[CV] END forest__max_depth=300, forest__max_features=60, forest__n_estimators=70; total time=  20.2s\n",
      "[CV] END forest__max_depth=300, forest__max_features=60, forest__n_estimators=70; total time=  19.6s\n",
      "[CV] END forest__max_depth=300, forest__max_features=75, forest__n_estimators=30; total time=   8.4s\n",
      "[CV] END forest__max_depth=300, forest__max_features=75, forest__n_estimators=30; total time=   8.6s\n",
      "[CV] END forest__max_depth=300, forest__max_features=75, forest__n_estimators=30; total time=   8.1s\n",
      "[CV] END forest__max_depth=300, forest__max_features=75, forest__n_estimators=30; total time=   8.6s\n",
      "[CV] END forest__max_depth=300, forest__max_features=75, forest__n_estimators=30; total time=   8.4s\n",
      "[CV] END forest__max_depth=300, forest__max_features=75, forest__n_estimators=50; total time=  14.3s\n",
      "[CV] END forest__max_depth=300, forest__max_features=75, forest__n_estimators=50; total time=  14.5s\n",
      "[CV] END forest__max_depth=300, forest__max_features=75, forest__n_estimators=50; total time=  13.8s\n",
      "[CV] END forest__max_depth=300, forest__max_features=75, forest__n_estimators=50; total time=  14.4s\n",
      "[CV] END forest__max_depth=300, forest__max_features=75, forest__n_estimators=50; total time=  14.0s\n",
      "[CV] END forest__max_depth=300, forest__max_features=75, forest__n_estimators=70; total time=  19.8s\n",
      "[CV] END forest__max_depth=300, forest__max_features=75, forest__n_estimators=70; total time=  20.2s\n",
      "[CV] END forest__max_depth=300, forest__max_features=75, forest__n_estimators=70; total time=  19.4s\n",
      "[CV] END forest__max_depth=300, forest__max_features=75, forest__n_estimators=70; total time=  20.1s\n",
      "[CV] END forest__max_depth=300, forest__max_features=75, forest__n_estimators=70; total time=  19.7s\n",
      "[CV] END forest__max_depth=300, forest__max_features=90, forest__n_estimators=30; total time=   8.4s\n",
      "[CV] END forest__max_depth=300, forest__max_features=90, forest__n_estimators=30; total time=   8.7s\n",
      "[CV] END forest__max_depth=300, forest__max_features=90, forest__n_estimators=30; total time=   8.3s\n",
      "[CV] END forest__max_depth=300, forest__max_features=90, forest__n_estimators=30; total time=   8.6s\n",
      "[CV] END forest__max_depth=300, forest__max_features=90, forest__n_estimators=30; total time=   8.2s\n",
      "[CV] END forest__max_depth=300, forest__max_features=90, forest__n_estimators=50; total time=  14.3s\n",
      "[CV] END forest__max_depth=300, forest__max_features=90, forest__n_estimators=50; total time=  14.4s\n",
      "[CV] END forest__max_depth=300, forest__max_features=90, forest__n_estimators=50; total time=  13.9s\n",
      "[CV] END forest__max_depth=300, forest__max_features=90, forest__n_estimators=50; total time=  14.1s\n",
      "[CV] END forest__max_depth=300, forest__max_features=90, forest__n_estimators=50; total time=  13.7s\n",
      "[CV] END forest__max_depth=300, forest__max_features=90, forest__n_estimators=70; total time=  19.7s\n",
      "[CV] END forest__max_depth=300, forest__max_features=90, forest__n_estimators=70; total time=  20.5s\n",
      "[CV] END forest__max_depth=300, forest__max_features=90, forest__n_estimators=70; total time=  19.8s\n",
      "[CV] END forest__max_depth=300, forest__max_features=90, forest__n_estimators=70; total time=  20.2s\n",
      "[CV] END forest__max_depth=300, forest__max_features=90, forest__n_estimators=70; total time=  19.6s\n",
      "[CV] END forest__max_depth=500, forest__max_features=60, forest__n_estimators=30; total time=  11.3s\n",
      "[CV] END forest__max_depth=500, forest__max_features=60, forest__n_estimators=30; total time=  11.6s\n",
      "[CV] END forest__max_depth=500, forest__max_features=60, forest__n_estimators=30; total time=  11.1s\n",
      "[CV] END forest__max_depth=500, forest__max_features=60, forest__n_estimators=30; total time=  11.5s\n",
      "[CV] END forest__max_depth=500, forest__max_features=60, forest__n_estimators=30; total time=  11.3s\n",
      "[CV] END forest__max_depth=500, forest__max_features=60, forest__n_estimators=50; total time=  18.8s\n",
      "[CV] END forest__max_depth=500, forest__max_features=60, forest__n_estimators=50; total time=  19.4s\n",
      "[CV] END forest__max_depth=500, forest__max_features=60, forest__n_estimators=50; total time=  18.6s\n",
      "[CV] END forest__max_depth=500, forest__max_features=60, forest__n_estimators=50; total time=  19.3s\n",
      "[CV] END forest__max_depth=500, forest__max_features=60, forest__n_estimators=50; total time=  18.9s\n",
      "[CV] END forest__max_depth=500, forest__max_features=60, forest__n_estimators=70; total time=  26.4s\n",
      "[CV] END forest__max_depth=500, forest__max_features=60, forest__n_estimators=70; total time=  27.3s\n",
      "[CV] END forest__max_depth=500, forest__max_features=60, forest__n_estimators=70; total time=  26.2s\n",
      "[CV] END forest__max_depth=500, forest__max_features=60, forest__n_estimators=70; total time=  27.4s\n",
      "[CV] END forest__max_depth=500, forest__max_features=60, forest__n_estimators=70; total time=  26.8s\n",
      "[CV] END forest__max_depth=500, forest__max_features=75, forest__n_estimators=30; total time=  11.1s\n",
      "[CV] END forest__max_depth=500, forest__max_features=75, forest__n_estimators=30; total time=  11.3s\n",
      "[CV] END forest__max_depth=500, forest__max_features=75, forest__n_estimators=30; total time=  11.0s\n",
      "[CV] END forest__max_depth=500, forest__max_features=75, forest__n_estimators=30; total time=  11.3s\n",
      "[CV] END forest__max_depth=500, forest__max_features=75, forest__n_estimators=30; total time=  11.1s\n",
      "[CV] END forest__max_depth=500, forest__max_features=75, forest__n_estimators=50; total time=  18.5s\n",
      "[CV] END forest__max_depth=500, forest__max_features=75, forest__n_estimators=50; total time=  18.9s\n",
      "[CV] END forest__max_depth=500, forest__max_features=75, forest__n_estimators=50; total time=  18.3s\n",
      "[CV] END forest__max_depth=500, forest__max_features=75, forest__n_estimators=50; total time=  19.0s\n",
      "[CV] END forest__max_depth=500, forest__max_features=75, forest__n_estimators=50; total time=  18.6s\n",
      "[CV] END forest__max_depth=500, forest__max_features=75, forest__n_estimators=70; total time=  25.9s\n",
      "[CV] END forest__max_depth=500, forest__max_features=75, forest__n_estimators=70; total time=  26.5s\n",
      "[CV] END forest__max_depth=500, forest__max_features=75, forest__n_estimators=70; total time=  25.1s\n",
      "[CV] END forest__max_depth=500, forest__max_features=75, forest__n_estimators=70; total time=  25.9s\n",
      "[CV] END forest__max_depth=500, forest__max_features=75, forest__n_estimators=70; total time=  25.5s\n",
      "[CV] END forest__max_depth=500, forest__max_features=90, forest__n_estimators=30; total time=  10.7s\n",
      "[CV] END forest__max_depth=500, forest__max_features=90, forest__n_estimators=30; total time=  11.2s\n",
      "[CV] END forest__max_depth=500, forest__max_features=90, forest__n_estimators=30; total time=  10.6s\n",
      "[CV] END forest__max_depth=500, forest__max_features=90, forest__n_estimators=30; total time=  11.1s\n",
      "[CV] END forest__max_depth=500, forest__max_features=90, forest__n_estimators=30; total time=  10.9s\n",
      "[CV] END forest__max_depth=500, forest__max_features=90, forest__n_estimators=50; total time=  18.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END forest__max_depth=500, forest__max_features=90, forest__n_estimators=50; total time=  18.5s\n",
      "[CV] END forest__max_depth=500, forest__max_features=90, forest__n_estimators=50; total time=  17.6s\n",
      "[CV] END forest__max_depth=500, forest__max_features=90, forest__n_estimators=50; total time=  18.3s\n",
      "[CV] END forest__max_depth=500, forest__max_features=90, forest__n_estimators=50; total time=  18.1s\n",
      "[CV] END forest__max_depth=500, forest__max_features=90, forest__n_estimators=70; total time=  25.1s\n",
      "[CV] END forest__max_depth=500, forest__max_features=90, forest__n_estimators=70; total time=  26.0s\n",
      "[CV] END forest__max_depth=500, forest__max_features=90, forest__n_estimators=70; total time=  24.7s\n",
      "[CV] END forest__max_depth=500, forest__max_features=90, forest__n_estimators=70; total time=  25.3s\n",
      "[CV] END forest__max_depth=500, forest__max_features=90, forest__n_estimators=70; total time=  25.2s\n",
      "[CV] END forest__max_depth=None, forest__max_features=60, forest__n_estimators=30; total time=  11.1s\n",
      "[CV] END forest__max_depth=None, forest__max_features=60, forest__n_estimators=30; total time=  11.3s\n",
      "[CV] END forest__max_depth=None, forest__max_features=60, forest__n_estimators=30; total time=  11.0s\n",
      "[CV] END forest__max_depth=None, forest__max_features=60, forest__n_estimators=30; total time=  11.3s\n",
      "[CV] END forest__max_depth=None, forest__max_features=60, forest__n_estimators=30; total time=  11.1s\n",
      "[CV] END forest__max_depth=None, forest__max_features=60, forest__n_estimators=50; total time=  18.8s\n",
      "[CV] END forest__max_depth=None, forest__max_features=60, forest__n_estimators=50; total time=  19.2s\n",
      "[CV] END forest__max_depth=None, forest__max_features=60, forest__n_estimators=50; total time=  19.0s\n",
      "[CV] END forest__max_depth=None, forest__max_features=60, forest__n_estimators=50; total time=  19.3s\n",
      "[CV] END forest__max_depth=None, forest__max_features=60, forest__n_estimators=50; total time=  18.9s\n",
      "[CV] END forest__max_depth=None, forest__max_features=60, forest__n_estimators=70; total time=  25.9s\n",
      "[CV] END forest__max_depth=None, forest__max_features=60, forest__n_estimators=70; total time=  26.8s\n",
      "[CV] END forest__max_depth=None, forest__max_features=60, forest__n_estimators=70; total time=  26.1s\n",
      "[CV] END forest__max_depth=None, forest__max_features=60, forest__n_estimators=70; total time=  26.4s\n",
      "[CV] END forest__max_depth=None, forest__max_features=60, forest__n_estimators=70; total time=  26.5s\n",
      "[CV] END forest__max_depth=None, forest__max_features=75, forest__n_estimators=30; total time=  11.0s\n",
      "[CV] END forest__max_depth=None, forest__max_features=75, forest__n_estimators=30; total time=  11.2s\n",
      "[CV] END forest__max_depth=None, forest__max_features=75, forest__n_estimators=30; total time=  10.8s\n",
      "[CV] END forest__max_depth=None, forest__max_features=75, forest__n_estimators=30; total time=  11.2s\n",
      "[CV] END forest__max_depth=None, forest__max_features=75, forest__n_estimators=30; total time=  11.2s\n",
      "[CV] END forest__max_depth=None, forest__max_features=75, forest__n_estimators=50; total time=  18.2s\n",
      "[CV] END forest__max_depth=None, forest__max_features=75, forest__n_estimators=50; total time=  19.3s\n",
      "[CV] END forest__max_depth=None, forest__max_features=75, forest__n_estimators=50; total time=  18.2s\n",
      "[CV] END forest__max_depth=None, forest__max_features=75, forest__n_estimators=50; total time=  18.7s\n",
      "[CV] END forest__max_depth=None, forest__max_features=75, forest__n_estimators=50; total time=  18.4s\n",
      "[CV] END forest__max_depth=None, forest__max_features=75, forest__n_estimators=70; total time=  25.4s\n",
      "[CV] END forest__max_depth=None, forest__max_features=75, forest__n_estimators=70; total time=  26.3s\n",
      "[CV] END forest__max_depth=None, forest__max_features=75, forest__n_estimators=70; total time=  25.3s\n",
      "[CV] END forest__max_depth=None, forest__max_features=75, forest__n_estimators=70; total time=  26.2s\n",
      "[CV] END forest__max_depth=None, forest__max_features=75, forest__n_estimators=70; total time=  26.2s\n",
      "[CV] END forest__max_depth=None, forest__max_features=90, forest__n_estimators=30; total time=  11.0s\n",
      "[CV] END forest__max_depth=None, forest__max_features=90, forest__n_estimators=30; total time=  11.2s\n",
      "[CV] END forest__max_depth=None, forest__max_features=90, forest__n_estimators=30; total time=  10.6s\n",
      "[CV] END forest__max_depth=None, forest__max_features=90, forest__n_estimators=30; total time=  10.9s\n",
      "[CV] END forest__max_depth=None, forest__max_features=90, forest__n_estimators=30; total time=  10.8s\n",
      "[CV] END forest__max_depth=None, forest__max_features=90, forest__n_estimators=50; total time=  17.9s\n",
      "[CV] END forest__max_depth=None, forest__max_features=90, forest__n_estimators=50; total time=  18.7s\n",
      "[CV] END forest__max_depth=None, forest__max_features=90, forest__n_estimators=50; total time=  17.9s\n",
      "[CV] END forest__max_depth=None, forest__max_features=90, forest__n_estimators=50; total time=  18.3s\n",
      "[CV] END forest__max_depth=None, forest__max_features=90, forest__n_estimators=50; total time=  18.2s\n",
      "[CV] END forest__max_depth=None, forest__max_features=90, forest__n_estimators=70; total time=  25.0s\n",
      "[CV] END forest__max_depth=None, forest__max_features=90, forest__n_estimators=70; total time=  26.3s\n",
      "[CV] END forest__max_depth=None, forest__max_features=90, forest__n_estimators=70; total time=  25.1s\n",
      "[CV] END forest__max_depth=None, forest__max_features=90, forest__n_estimators=70; total time=  25.5s\n",
      "[CV] END forest__max_depth=None, forest__max_features=90, forest__n_estimators=70; total time=  25.7s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;cv&#x27;,\n",
       "                                        CountVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                                       (&#x27;forest&#x27;,\n",
       "                                        RandomForestClassifier(random_state=333))]),\n",
       "             param_grid={&#x27;forest__max_depth&#x27;: [300, 500, None],\n",
       "                         &#x27;forest__max_features&#x27;: [60, 75, 90],\n",
       "                         &#x27;forest__n_estimators&#x27;: [30, 50, 70]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;cv&#x27;,\n",
       "                                        CountVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                                       (&#x27;forest&#x27;,\n",
       "                                        RandomForestClassifier(random_state=333))]),\n",
       "             param_grid={&#x27;forest__max_depth&#x27;: [300, 500, None],\n",
       "                         &#x27;forest__max_features&#x27;: [60, 75, 90],\n",
       "                         &#x27;forest__n_estimators&#x27;: [30, 50, 70]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;cv&#x27;, CountVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;forest&#x27;, RandomForestClassifier(random_state=333))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(stop_words=&#x27;english&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=333)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cv',\n",
       "                                        CountVectorizer(stop_words='english')),\n",
       "                                       ('forest',\n",
       "                                        RandomForestClassifier(random_state=333))]),\n",
       "             param_grid={'forest__max_depth': [300, 500, None],\n",
       "                         'forest__max_features': [60, 75, 90],\n",
       "                         'forest__n_estimators': [30, 50, 70]},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating parameters for GridSearch\n",
    "params3 = {'forest__max_depth': [300, 500, None],\n",
    "         'forest__max_features': [60, 75, 90],\n",
    "         'forest__n_estimators': [30, 50, 70]}\n",
    "# GridSearch with the random forest pipeline, parameters above, 5 fold cross validation, and accuracy score\n",
    "forest_grid3 = GridSearchCV(estimator=forest_pipe, param_grid=params3, cv=5, scoring='accuracy', verbose=2)\n",
    "# Fitting the GridSearch\n",
    "forest_grid3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GridSearch discovered max_depth=300, max_features=90, and n_estimators=70 had the best cross validation score. This improvement was minimal from the previous GridSearch iteration so we decided to move on to a new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('cv', CountVectorizer(stop_words='english')),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(max_depth=300, max_features=90,\n",
      "                                        n_estimators=70, random_state=333))])\n",
      "0.6877062116709517\n"
     ]
    }
   ],
   "source": [
    "# Displaying the best estimator from the GridSearch and the accuracy score\n",
    "print(forest_grid3.best_estimator_)\n",
    "print(forest_grid3.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third Model (Logistic Regression)\n",
    "\n",
    "Created a logistic regression model with an awareness that logistic regression does not handle class imbalances as well as decision trees/random forests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;cv&#x27;, CountVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;logreg&#x27;,\n",
       "                 LogisticRegression(max_iter=1000, random_state=333))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" ><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;cv&#x27;, CountVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;logreg&#x27;,\n",
       "                 LogisticRegression(max_iter=1000, random_state=333))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" ><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(stop_words=&#x27;english&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" ><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, random_state=333)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('cv', CountVectorizer(stop_words='english')),\n",
       "                ('logreg',\n",
       "                 LogisticRegression(max_iter=1000, random_state=333))])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating steps for a Pipeline \n",
    "logreg_steps = [('cv', CountVectorizer(stop_words='english')),\n",
    "         ('logreg', LogisticRegression(random_state=333, max_iter=1000))]\n",
    "# Feeding the Pipeline the steps defined above\n",
    "logreg_pipe = Pipeline(logreg_steps)\n",
    "# Fitting the training data to the Pipeline\n",
    "logreg_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This logistic regression has an 88% accuracy score which is pretty high but it could be overfit to the training data and probably isn't doing well with the class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8836168307967771"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the predictions from the Pipeline using the training data\n",
    "y_pred = logreg_pipe.predict(X_train)\n",
    "# Evaluating the accuracy score on the training data\n",
    "accuracy_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created confusion matrix in order to investigate how the model is handling the class imbalance. It shows that this model is struggling predicting the negative and positive sentiments accurately but is doing pretty well with the neutral sentiment becuase most of the data is neutral. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1c5c4c598b0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf = confusion_matrix(y_train, y_pred)\n",
    "ConfusionMatrixDisplay(cf, display_labels=['Negative', 'Neutral', 'Positive']).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared the training results to a cross validation score. This shows the model is also very overfit because of the much lower cross validation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6883016683918216"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating mean of the 5-fold cross_val_score\n",
    "cross_val_score(logreg_pipe, X_train, y_train, cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with GridSearch\n",
    "\n",
    "In order to combat the poor performance due to overfitting and the class imbalance, we used a GridSearch to help tune the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV 1/5] END logreg__C=0.1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.676 total time=   0.1s\n",
      "[CV 2/5] END logreg__C=0.1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.682 total time=   0.1s\n",
      "[CV 3/5] END logreg__C=0.1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.676 total time=   0.1s\n",
      "[CV 4/5] END logreg__C=0.1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.684 total time=   0.1s\n",
      "[CV 5/5] END logreg__C=0.1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.684 total time=   0.2s\n",
      "[CV 1/5] END logreg__C=0.1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=sag;, score=0.676 total time=   0.1s\n",
      "[CV 2/5] END logreg__C=0.1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=sag;, score=0.682 total time=   0.0s\n",
      "[CV 3/5] END logreg__C=0.1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=sag;, score=0.676 total time=   0.0s\n",
      "[CV 4/5] END logreg__C=0.1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=sag;, score=0.684 total time=   0.0s\n",
      "[CV 5/5] END logreg__C=0.1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=sag;, score=0.684 total time=   0.0s\n",
      "[CV 1/5] END logreg__C=0.1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.676 total time=   0.1s\n",
      "[CV 2/5] END logreg__C=0.1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.682 total time=   0.1s\n",
      "[CV 3/5] END logreg__C=0.1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.676 total time=   0.1s\n",
      "[CV 4/5] END logreg__C=0.1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.684 total time=   0.2s\n",
      "[CV 5/5] END logreg__C=0.1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.684 total time=   0.1s\n",
      "[CV 1/5] END logreg__C=0.1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=saga;, score=0.676 total time=   0.3s\n",
      "[CV 2/5] END logreg__C=0.1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=saga;, score=0.682 total time=   0.3s\n",
      "[CV 3/5] END logreg__C=0.1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=saga;, score=0.676 total time=   0.3s\n",
      "[CV 4/5] END logreg__C=0.1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=saga;, score=0.684 total time=   0.3s\n",
      "[CV 5/5] END logreg__C=0.1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=saga;, score=0.684 total time=   0.3s\n",
      "[CV 1/5] END logreg__C=0.1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.610 total time=   0.1s\n",
      "[CV 2/5] END logreg__C=0.1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.640 total time=   0.1s\n",
      "[CV 3/5] END logreg__C=0.1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.624 total time=   0.1s\n",
      "[CV 4/5] END logreg__C=0.1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.629 total time=   0.1s\n",
      "[CV 5/5] END logreg__C=0.1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.633 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logreg__C=0.1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=sag;, score=0.611 total time=   7.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logreg__C=0.1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=sag;, score=0.638 total time=   7.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logreg__C=0.1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=sag;, score=0.622 total time=   8.1s\n",
      "[CV 4/5] END logreg__C=0.1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=sag;, score=0.629 total time=   7.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logreg__C=0.1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=sag;, score=0.629 total time=   8.0s\n",
      "[CV 1/5] END logreg__C=0.1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.610 total time=   0.2s\n",
      "[CV 2/5] END logreg__C=0.1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.640 total time=   0.2s\n",
      "[CV 3/5] END logreg__C=0.1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.624 total time=   0.2s\n",
      "[CV 4/5] END logreg__C=0.1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.629 total time=   0.2s\n",
      "[CV 5/5] END logreg__C=0.1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.633 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logreg__C=0.1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=saga;, score=0.606 total time=   8.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logreg__C=0.1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=saga;, score=0.651 total time=   8.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logreg__C=0.1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=saga;, score=0.622 total time=   8.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logreg__C=0.1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=saga;, score=0.628 total time=   8.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logreg__C=0.1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=saga;, score=0.631 total time=   8.7s\n",
      "[CV 1/5] END logreg__C=0.1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END logreg__C=0.1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END logreg__C=0.1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END logreg__C=0.1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END logreg__C=0.1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END logreg__C=0.1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END logreg__C=0.1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END logreg__C=0.1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END logreg__C=0.1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END logreg__C=0.1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END logreg__C=0.1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END logreg__C=0.1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END logreg__C=0.1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END logreg__C=0.1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END logreg__C=0.1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END logreg__C=0.1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END logreg__C=0.1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END logreg__C=0.1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END logreg__C=0.1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END logreg__C=0.1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END logreg__C=1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.685 total time=   0.3s\n",
      "[CV 2/5] END logreg__C=1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.694 total time=   0.5s\n",
      "[CV 3/5] END logreg__C=1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.683 total time=   0.3s\n",
      "[CV 4/5] END logreg__C=1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.690 total time=   0.3s\n",
      "[CV 5/5] END logreg__C=1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.690 total time=   0.3s\n",
      "[CV 1/5] END logreg__C=1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=sag;, score=0.685 total time=   0.2s\n",
      "[CV 2/5] END logreg__C=1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=sag;, score=0.694 total time=   0.1s\n",
      "[CV 3/5] END logreg__C=1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=sag;, score=0.683 total time=   0.1s\n",
      "[CV 4/5] END logreg__C=1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=sag;, score=0.690 total time=   0.1s\n",
      "[CV 5/5] END logreg__C=1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=sag;, score=0.690 total time=   0.1s\n",
      "[CV 1/5] END logreg__C=1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.685 total time=   0.3s\n",
      "[CV 2/5] END logreg__C=1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.694 total time=   0.2s\n",
      "[CV 3/5] END logreg__C=1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.683 total time=   0.2s\n",
      "[CV 4/5] END logreg__C=1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.690 total time=   0.2s\n",
      "[CV 5/5] END logreg__C=1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.690 total time=   0.2s\n",
      "[CV 1/5] END logreg__C=1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=saga;, score=0.685 total time=   0.4s\n",
      "[CV 2/5] END logreg__C=1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=saga;, score=0.695 total time=   0.4s\n",
      "[CV 3/5] END logreg__C=1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=saga;, score=0.683 total time=   0.3s\n",
      "[CV 4/5] END logreg__C=1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=saga;, score=0.690 total time=   0.4s\n",
      "[CV 5/5] END logreg__C=1, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=saga;, score=0.692 total time=   0.4s\n",
      "[CV 1/5] END logreg__C=1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.641 total time=   0.3s\n",
      "[CV 2/5] END logreg__C=1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.665 total time=   0.3s\n",
      "[CV 3/5] END logreg__C=1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.645 total time=   0.5s\n",
      "[CV 4/5] END logreg__C=1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.654 total time=   0.3s\n",
      "[CV 5/5] END logreg__C=1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.649 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logreg__C=1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=sag;, score=0.637 total time=   7.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logreg__C=1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=sag;, score=0.668 total time=   7.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logreg__C=1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=sag;, score=0.643 total time=   8.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logreg__C=1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=sag;, score=0.653 total time=   8.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logreg__C=1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=sag;, score=0.646 total time=   7.9s\n",
      "[CV 1/5] END logreg__C=1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.641 total time=   0.2s\n",
      "[CV 2/5] END logreg__C=1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.665 total time=   0.2s\n",
      "[CV 3/5] END logreg__C=1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.645 total time=   0.2s\n",
      "[CV 4/5] END logreg__C=1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.654 total time=   0.2s\n",
      "[CV 5/5] END logreg__C=1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.649 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logreg__C=1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=saga;, score=0.640 total time=   8.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logreg__C=1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=saga;, score=0.665 total time=   8.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logreg__C=1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=saga;, score=0.646 total time=   8.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logreg__C=1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=saga;, score=0.657 total time=   8.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logreg__C=1, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=saga;, score=0.649 total time=   8.4s\n",
      "[CV 1/5] END logreg__C=1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END logreg__C=1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END logreg__C=1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END logreg__C=1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END logreg__C=1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END logreg__C=1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END logreg__C=1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END logreg__C=1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END logreg__C=1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END logreg__C=1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END logreg__C=1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END logreg__C=1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END logreg__C=1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END logreg__C=1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END logreg__C=1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END logreg__C=1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END logreg__C=1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END logreg__C=1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END logreg__C=1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END logreg__C=1, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END logreg__C=10, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.660 total time=   0.7s\n",
      "[CV 2/5] END logreg__C=10, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.670 total time=   0.7s\n",
      "[CV 3/5] END logreg__C=10, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.655 total time=   0.7s\n",
      "[CV 4/5] END logreg__C=10, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.675 total time=   0.6s\n",
      "[CV 5/5] END logreg__C=10, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.680 total time=   0.8s\n",
      "[CV 1/5] END logreg__C=10, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=sag;, score=0.661 total time=   0.5s\n",
      "[CV 2/5] END logreg__C=10, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=sag;, score=0.670 total time=   0.5s\n",
      "[CV 3/5] END logreg__C=10, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=sag;, score=0.655 total time=   0.5s\n",
      "[CV 4/5] END logreg__C=10, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=sag;, score=0.674 total time=   0.5s\n",
      "[CV 5/5] END logreg__C=10, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=sag;, score=0.680 total time=   0.6s\n",
      "[CV 1/5] END logreg__C=10, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.661 total time=   0.5s\n",
      "[CV 2/5] END logreg__C=10, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.670 total time=   0.4s\n",
      "[CV 3/5] END logreg__C=10, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.655 total time=   0.6s\n",
      "[CV 4/5] END logreg__C=10, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.675 total time=   0.4s\n",
      "[CV 5/5] END logreg__C=10, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.680 total time=   0.5s\n",
      "[CV 1/5] END logreg__C=10, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=saga;, score=0.661 total time=   1.2s\n",
      "[CV 2/5] END logreg__C=10, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=saga;, score=0.670 total time=   1.0s\n",
      "[CV 3/5] END logreg__C=10, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=saga;, score=0.654 total time=   1.0s\n",
      "[CV 4/5] END logreg__C=10, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=saga;, score=0.674 total time=   1.2s\n",
      "[CV 5/5] END logreg__C=10, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=saga;, score=0.679 total time=   1.2s\n",
      "[CV 1/5] END logreg__C=10, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.632 total time=   0.7s\n",
      "[CV 2/5] END logreg__C=10, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.644 total time=   0.7s\n",
      "[CV 3/5] END logreg__C=10, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.634 total time=   0.7s\n",
      "[CV 4/5] END logreg__C=10, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.659 total time=   0.7s\n",
      "[CV 5/5] END logreg__C=10, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.649 total time=   0.7s\n",
      "[CV 1/5] END logreg__C=10, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=sag;, score=0.632 total time=   0.6s\n",
      "[CV 2/5] END logreg__C=10, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=sag;, score=0.644 total time=   0.8s\n",
      "[CV 3/5] END logreg__C=10, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=sag;, score=0.635 total time=   0.5s\n",
      "[CV 4/5] END logreg__C=10, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=sag;, score=0.659 total time=   1.2s\n",
      "[CV 5/5] END logreg__C=10, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=sag;, score=0.648 total time=   0.7s\n",
      "[CV 1/5] END logreg__C=10, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.632 total time=   0.4s\n",
      "[CV 2/5] END logreg__C=10, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.644 total time=   0.4s\n",
      "[CV 3/5] END logreg__C=10, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.634 total time=   0.4s\n",
      "[CV 4/5] END logreg__C=10, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.659 total time=   0.4s\n",
      "[CV 5/5] END logreg__C=10, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.649 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logreg__C=10, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=saga;, score=0.633 total time=   9.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logreg__C=10, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=saga;, score=0.647 total time=   9.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logreg__C=10, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=saga;, score=0.634 total time=   9.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logreg__C=10, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=saga;, score=0.660 total time=   9.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logreg__C=10, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=saga;, score=0.649 total time=   8.7s\n",
      "[CV 1/5] END logreg__C=10, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END logreg__C=10, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END logreg__C=10, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END logreg__C=10, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END logreg__C=10, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END logreg__C=10, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END logreg__C=10, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END logreg__C=10, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END logreg__C=10, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END logreg__C=10, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END logreg__C=10, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END logreg__C=10, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END logreg__C=10, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END logreg__C=10, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END logreg__C=10, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END logreg__C=10, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END logreg__C=10, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END logreg__C=10, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END logreg__C=10, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END logreg__C=10, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END logreg__C=100, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.633 total time=   1.7s\n",
      "[CV 2/5] END logreg__C=100, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.658 total time=   1.6s\n",
      "[CV 3/5] END logreg__C=100, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.622 total time=   1.6s\n",
      "[CV 4/5] END logreg__C=100, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.662 total time=   1.7s\n",
      "[CV 5/5] END logreg__C=100, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.653 total time=   1.6s\n",
      "[CV 1/5] END logreg__C=100, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=sag;, score=0.633 total time=   1.7s\n",
      "[CV 2/5] END logreg__C=100, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=sag;, score=0.656 total time=   1.5s\n",
      "[CV 3/5] END logreg__C=100, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=sag;, score=0.621 total time=   1.7s\n",
      "[CV 4/5] END logreg__C=100, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=sag;, score=0.661 total time=   1.7s\n",
      "[CV 5/5] END logreg__C=100, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=sag;, score=0.655 total time=   1.8s\n",
      "[CV 1/5] END logreg__C=100, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.633 total time=   1.0s\n",
      "[CV 2/5] END logreg__C=100, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.658 total time=   1.1s\n",
      "[CV 3/5] END logreg__C=100, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.622 total time=   1.0s\n",
      "[CV 4/5] END logreg__C=100, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.662 total time=   1.1s\n",
      "[CV 5/5] END logreg__C=100, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.653 total time=   0.8s\n",
      "[CV 1/5] END logreg__C=100, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=saga;, score=0.635 total time=   2.6s\n",
      "[CV 2/5] END logreg__C=100, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=saga;, score=0.659 total time=   2.4s\n",
      "[CV 3/5] END logreg__C=100, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=saga;, score=0.622 total time=   2.7s\n",
      "[CV 4/5] END logreg__C=100, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=saga;, score=0.660 total time=   2.9s\n",
      "[CV 5/5] END logreg__C=100, logreg__class_weight=None, logreg__max_iter=5000, logreg__solver=saga;, score=0.657 total time=   2.9s\n",
      "[CV 1/5] END logreg__C=100, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.623 total time=   1.5s\n",
      "[CV 2/5] END logreg__C=100, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.639 total time=   1.7s\n",
      "[CV 3/5] END logreg__C=100, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.607 total time=   1.6s\n",
      "[CV 4/5] END logreg__C=100, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.641 total time=   1.7s\n",
      "[CV 5/5] END logreg__C=100, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=lbfgs;, score=0.637 total time=   1.6s\n",
      "[CV 1/5] END logreg__C=100, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=sag;, score=0.622 total time=   2.4s\n",
      "[CV 2/5] END logreg__C=100, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=sag;, score=0.639 total time=   2.2s\n",
      "[CV 3/5] END logreg__C=100, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=sag;, score=0.608 total time=   2.3s\n",
      "[CV 4/5] END logreg__C=100, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=sag;, score=0.641 total time=   2.3s\n",
      "[CV 5/5] END logreg__C=100, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=sag;, score=0.640 total time=   2.0s\n",
      "[CV 1/5] END logreg__C=100, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.623 total time=   0.8s\n",
      "[CV 2/5] END logreg__C=100, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.639 total time=   1.0s\n",
      "[CV 3/5] END logreg__C=100, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.607 total time=   0.7s\n",
      "[CV 4/5] END logreg__C=100, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.641 total time=   0.7s\n",
      "[CV 5/5] END logreg__C=100, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=newton-cg;, score=0.637 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logreg__C=100, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=saga;, score=0.623 total time=   8.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logreg__C=100, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=saga;, score=0.640 total time=   8.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logreg__C=100, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=saga;, score=0.607 total time=   8.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logreg__C=100, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=saga;, score=0.643 total time=   8.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logreg__C=100, logreg__class_weight=balanced, logreg__max_iter=5000, logreg__solver=saga;, score=0.639 total time=   8.7s\n",
      "[CV 1/5] END logreg__C=100, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END logreg__C=100, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END logreg__C=100, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END logreg__C=100, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END logreg__C=100, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END logreg__C=100, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END logreg__C=100, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END logreg__C=100, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END logreg__C=100, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END logreg__C=100, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END logreg__C=100, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END logreg__C=100, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END logreg__C=100, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END logreg__C=100, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END logreg__C=100, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END logreg__C=100, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END logreg__C=100, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END logreg__C=100, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END logreg__C=100, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END logreg__C=100, logreg__class_weight=[4, 1, 2], logreg__max_iter=5000, logreg__solver=saga;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "80 fits failed out of a total of 240.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'class_weight' parameter of LogisticRegression must be an instance of 'dict', a str among {'balanced'} or None. Got [4, 1, 2] instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.68039434 0.68039434 0.68039434 0.68024508 0.62712689 0.62578372\n",
      " 0.62712689 0.62742429        nan        nan        nan        nan\n",
      " 0.68830167 0.68830167 0.68830167 0.68889846 0.65084989 0.64920821\n",
      " 0.65084989 0.65159627        nan        nan        nan        nan\n",
      " 0.6680104  0.66801028 0.66815954 0.66786092 0.64354091 0.64354091\n",
      " 0.64354091 0.64458502        nan        nan        nan        nan\n",
      " 0.64577738 0.64532995 0.64577738 0.64682171 0.62951317 0.6301103\n",
      " 0.62951317 0.63011008        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;cv&#x27;,\n",
       "                                        CountVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                                       (&#x27;logreg&#x27;,\n",
       "                                        LogisticRegression(max_iter=1000,\n",
       "                                                           random_state=333))]),\n",
       "             param_grid={&#x27;logreg__C&#x27;: [0.1, 1, 10, 100],\n",
       "                         &#x27;logreg__class_weight&#x27;: [None, &#x27;balanced&#x27;, [4, 1, 2]],\n",
       "                         &#x27;logreg__max_iter&#x27;: [5000],\n",
       "                         &#x27;logreg__solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;sag&#x27;, &#x27;newton-cg&#x27;,\n",
       "                                            &#x27;saga&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-44\" type=\"checkbox\" ><label for=\"sk-estimator-id-44\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;cv&#x27;,\n",
       "                                        CountVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                                       (&#x27;logreg&#x27;,\n",
       "                                        LogisticRegression(max_iter=1000,\n",
       "                                                           random_state=333))]),\n",
       "             param_grid={&#x27;logreg__C&#x27;: [0.1, 1, 10, 100],\n",
       "                         &#x27;logreg__class_weight&#x27;: [None, &#x27;balanced&#x27;, [4, 1, 2]],\n",
       "                         &#x27;logreg__max_iter&#x27;: [5000],\n",
       "                         &#x27;logreg__solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;sag&#x27;, &#x27;newton-cg&#x27;,\n",
       "                                            &#x27;saga&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-45\" type=\"checkbox\" ><label for=\"sk-estimator-id-45\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;cv&#x27;, CountVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;logreg&#x27;,\n",
       "                 LogisticRegression(max_iter=1000, random_state=333))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-46\" type=\"checkbox\" ><label for=\"sk-estimator-id-46\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(stop_words=&#x27;english&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-47\" type=\"checkbox\" ><label for=\"sk-estimator-id-47\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, random_state=333)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cv',\n",
       "                                        CountVectorizer(stop_words='english')),\n",
       "                                       ('logreg',\n",
       "                                        LogisticRegression(max_iter=1000,\n",
       "                                                           random_state=333))]),\n",
       "             param_grid={'logreg__C': [0.1, 1, 10, 100],\n",
       "                         'logreg__class_weight': [None, 'balanced', [4, 1, 2]],\n",
       "                         'logreg__max_iter': [5000],\n",
       "                         'logreg__solver': ['lbfgs', 'sag', 'newton-cg',\n",
       "                                            'saga']},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating parameters for GridSearch\n",
    "logreg_params = {'logreg__class_weight':[None,'balanced', [4, 1, 2]],\n",
    "                'logreg__C': [0.1, 1, 10, 100],\n",
    "                'logreg__solver': ['lbfgs', 'sag', 'newton-cg', 'saga'],\n",
    "                'logreg__max_iter': [5000]}\n",
    "# GridSearch with the logistic regression pipeline, parameters above, 5 fold cross validation, and accuracy score\n",
    "logreg_grid = GridSearchCV(estimator=logreg_pipe, param_grid=logreg_params, cv=5, scoring='accuracy', verbose=3)\n",
    "# Fitting the GridSearch\n",
    "logreg_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GridSearch discovered C=1, max_iter=5000, default weights, and solver='saga' had the best cross validation score. This is a marginal improvement from our logistic regression with all default settings. Throughout the GridSearch, sometimes the max iterations was reached without the model converging. This model did not have the problem and the results can be trusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('cv', CountVectorizer(stop_words='english')),\n",
      "                ('logreg',\n",
      "                 LogisticRegression(C=1, max_iter=5000, random_state=333,\n",
      "                                    solver='saga'))])\n",
      "0.6888984607165515\n"
     ]
    }
   ],
   "source": [
    "print(logreg_grid.best_estimator_)\n",
    "print(logreg_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourth Model (Multinomial Naive Bayes)\n",
    "\n",
    "Created a Multinomial Naive Bayes (MNB) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;mnb&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-48\" type=\"checkbox\" ><label for=\"sk-estimator-id-48\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;mnb&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-49\" type=\"checkbox\" ><label for=\"sk-estimator-id-49\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-50\" type=\"checkbox\" ><label for=\"sk-estimator-id-50\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('mnb', MultinomialNB())])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating steps for a Pipeline \n",
    "mnb_steps = [('tfidf', TfidfVectorizer()),\n",
    "             ('mnb', MultinomialNB())]\n",
    "# Feeding the Pipeline the steps defined above\n",
    "mnb_pipe = Pipeline(mnb_steps)\n",
    "# Fitting the training data to the Pipeline\n",
    "mnb_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a lower accuracy score on the training data than on previous models that sparked hope it was not overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7593255744553864"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the predictions from the Pipeline using the training data\n",
    "y_pred = mnb_pipe.predict(X_train)\n",
    "# Evaluating the accuracy score on the training data\n",
    "accuracy_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a pretty low cross validation score and is in line with our previous models. It seemed to be a little less overfit than the previous models but, still is very overfit on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6674115997195231"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating mean of the 5-fold cross_val_score\n",
    "cross_val_score(mnb_pipe, X_train, y_train, cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNB with GridSearch\n",
    "\n",
    "Tried to improve the MNB model by adjusting hyperparameters using a GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 1/5] END .mnb__alpha=1, mnb__fit_prior=True;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END .mnb__alpha=1, mnb__fit_prior=True;, score=0.670 total time=   0.0s\n",
      "[CV 3/5] END .mnb__alpha=1, mnb__fit_prior=True;, score=0.663 total time=   0.0s\n",
      "[CV 4/5] END .mnb__alpha=1, mnb__fit_prior=True;, score=0.669 total time=   0.0s\n",
      "[CV 5/5] END .mnb__alpha=1, mnb__fit_prior=True;, score=0.663 total time=   0.0s\n",
      "[CV 1/5] END mnb__alpha=1, mnb__fit_prior=False;, score=0.652 total time=   0.0s\n",
      "[CV 2/5] END mnb__alpha=1, mnb__fit_prior=False;, score=0.662 total time=   0.0s\n",
      "[CV 3/5] END mnb__alpha=1, mnb__fit_prior=False;, score=0.643 total time=   0.0s\n",
      "[CV 4/5] END mnb__alpha=1, mnb__fit_prior=False;, score=0.649 total time=   0.0s\n",
      "[CV 5/5] END mnb__alpha=1, mnb__fit_prior=False;, score=0.666 total time=   0.0s\n",
      "[CV 1/5] END mnb__alpha=0.5, mnb__fit_prior=True;, score=0.667 total time=   0.0s\n",
      "[CV 2/5] END mnb__alpha=0.5, mnb__fit_prior=True;, score=0.679 total time=   0.0s\n",
      "[CV 3/5] END mnb__alpha=0.5, mnb__fit_prior=True;, score=0.669 total time=   0.0s\n",
      "[CV 4/5] END mnb__alpha=0.5, mnb__fit_prior=True;, score=0.672 total time=   0.0s\n",
      "[CV 5/5] END mnb__alpha=0.5, mnb__fit_prior=True;, score=0.674 total time=   0.0s\n",
      "[CV 1/5] END mnb__alpha=0.5, mnb__fit_prior=False;, score=0.641 total time=   0.0s\n",
      "[CV 2/5] END mnb__alpha=0.5, mnb__fit_prior=False;, score=0.651 total time=   0.0s\n",
      "[CV 3/5] END mnb__alpha=0.5, mnb__fit_prior=False;, score=0.637 total time=   0.0s\n",
      "[CV 4/5] END mnb__alpha=0.5, mnb__fit_prior=False;, score=0.630 total time=   0.0s\n",
      "[CV 5/5] END mnb__alpha=0.5, mnb__fit_prior=False;, score=0.651 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\naive_bayes.py:624: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\naive_bayes.py:633: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\naive_bayes.py:624: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\naive_bayes.py:633: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\naive_bayes.py:624: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\naive_bayes.py:633: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END .mnb__alpha=0, mnb__fit_prior=True;, score=0.655 total time=   0.0s\n",
      "[CV 2/5] END .mnb__alpha=0, mnb__fit_prior=True;, score=0.660 total time=   0.0s\n",
      "[CV 3/5] END .mnb__alpha=0, mnb__fit_prior=True;, score=0.666 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\naive_bayes.py:624: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\naive_bayes.py:633: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\naive_bayes.py:624: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\naive_bayes.py:633: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\naive_bayes.py:624: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\naive_bayes.py:633: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END .mnb__alpha=0, mnb__fit_prior=True;, score=0.648 total time=   0.0s\n",
      "[CV 5/5] END .mnb__alpha=0, mnb__fit_prior=True;, score=0.672 total time=   0.0s\n",
      "[CV 1/5] END mnb__alpha=0, mnb__fit_prior=False;, score=0.587 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\naive_bayes.py:624: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\naive_bayes.py:633: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\naive_bayes.py:624: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\naive_bayes.py:633: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\naive_bayes.py:624: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\naive_bayes.py:633: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END mnb__alpha=0, mnb__fit_prior=False;, score=0.614 total time=   0.0s\n",
      "[CV 3/5] END mnb__alpha=0, mnb__fit_prior=False;, score=0.608 total time=   0.0s\n",
      "[CV 4/5] END mnb__alpha=0, mnb__fit_prior=False;, score=0.599 total time=   0.0s\n",
      "[CV 5/5] END mnb__alpha=0, mnb__fit_prior=False;, score=0.620 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\naive_bayes.py:624: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\naive_bayes.py:633: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                                       (&#x27;mnb&#x27;, MultinomialNB())]),\n",
       "             param_grid={&#x27;mnb__alpha&#x27;: [1, 0.5, 0],\n",
       "                         &#x27;mnb__fit_prior&#x27;: [True, False]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-51\" type=\"checkbox\" ><label for=\"sk-estimator-id-51\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                                       (&#x27;mnb&#x27;, MultinomialNB())]),\n",
       "             param_grid={&#x27;mnb__alpha&#x27;: [1, 0.5, 0],\n",
       "                         &#x27;mnb__fit_prior&#x27;: [True, False]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-52\" type=\"checkbox\" ><label for=\"sk-estimator-id-52\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;mnb&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-53\" type=\"checkbox\" ><label for=\"sk-estimator-id-53\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-54\" type=\"checkbox\" ><label for=\"sk-estimator-id-54\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                       ('mnb', MultinomialNB())]),\n",
       "             param_grid={'mnb__alpha': [1, 0.5, 0],\n",
       "                         'mnb__fit_prior': [True, False]},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating parameters for GridSearch\n",
    "mnb_params = {'mnb__alpha':[1, 0.5, 0],\n",
    "          'mnb__fit_prior':[True, False]}\n",
    "# GridSearch with the logistic regression pipeline, parameters above, 5 fold cross validation, and accuracy score\n",
    "mnb_grid = GridSearchCV(estimator=mnb_pipe, param_grid=mnb_params, cv=5, scoring='accuracy', verbose=3)\n",
    "# Fitting the GridSearch\n",
    "mnb_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This did not improve much from the accuracy score using the defualt parameters but, it did improve about 0.5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
      "                ('mnb', MultinomialNB(alpha=0.5))])\n",
      "0.6720380201898783\n"
     ]
    }
   ],
   "source": [
    "print(mnb_grid.best_estimator_)\n",
    "print(mnb_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Random Forest, Logistic Regression, and MNB Models\n",
    "\n",
    "Attempted to make an improved model by stacking the other models together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the estimators to feed the stacked classifier\n",
    "estimators = [('forest', RandomForestClassifier(random_state=333)),\n",
    " ('logreg', LogisticRegression(random_state=333)),\n",
    " ('mnb', MultinomialNB())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feeding the estimators to teh stacking classifier\n",
    "sc = StackingClassifier(estimators=estimators)\n",
    "# Instantiating standard scaler\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "\n",
    "# Creating stacking classifier Pipeline\n",
    "sc_pipe = Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
    "                          ('scaler', scaler),\n",
    "                          ('sc', sc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-17 {color: black;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;scaler&#x27;, StandardScaler(with_mean=False)),\n",
       "                (&#x27;sc&#x27;,\n",
       "                 StackingClassifier(estimators=[(&#x27;forest&#x27;,\n",
       "                                                 RandomForestClassifier(random_state=333)),\n",
       "                                                (&#x27;logreg&#x27;,\n",
       "                                                 LogisticRegression(random_state=333)),\n",
       "                                                (&#x27;mnb&#x27;, MultinomialNB())]))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-63\" type=\"checkbox\" ><label for=\"sk-estimator-id-63\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;scaler&#x27;, StandardScaler(with_mean=False)),\n",
       "                (&#x27;sc&#x27;,\n",
       "                 StackingClassifier(estimators=[(&#x27;forest&#x27;,\n",
       "                                                 RandomForestClassifier(random_state=333)),\n",
       "                                                (&#x27;logreg&#x27;,\n",
       "                                                 LogisticRegression(random_state=333)),\n",
       "                                                (&#x27;mnb&#x27;, MultinomialNB())]))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-64\" type=\"checkbox\" ><label for=\"sk-estimator-id-64\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-65\" type=\"checkbox\" ><label for=\"sk-estimator-id-65\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler(with_mean=False)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-66\" type=\"checkbox\" ><label for=\"sk-estimator-id-66\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">sc: StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(estimators=[(&#x27;forest&#x27;,\n",
       "                                RandomForestClassifier(random_state=333)),\n",
       "                               (&#x27;logreg&#x27;, LogisticRegression(random_state=333)),\n",
       "                               (&#x27;mnb&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>forest</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-67\" type=\"checkbox\" ><label for=\"sk-estimator-id-67\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=333)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>logreg</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-68\" type=\"checkbox\" ><label for=\"sk-estimator-id-68\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=333)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>mnb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-69\" type=\"checkbox\" ><label for=\"sk-estimator-id-69\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-70\" type=\"checkbox\" ><label for=\"sk-estimator-id-70\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('scaler', StandardScaler(with_mean=False)),\n",
       "                ('sc',\n",
       "                 StackingClassifier(estimators=[('forest',\n",
       "                                                 RandomForestClassifier(random_state=333)),\n",
       "                                                ('logreg',\n",
       "                                                 LogisticRegression(random_state=333)),\n",
       "                                                ('mnb', MultinomialNB())]))])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9580722172485825"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = sc_pipe.predict(X_train)\n",
    "accuracy_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'Final' Model\n",
    "\n",
    "In the end, you'll arrive at a 'final' model - aka the one you'll use to make your recommendations/conclusions. This likely blends any group work. It might not be the one with the highest scores, but instead might be considered 'final' or 'best' for other reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here to show your final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here to evaluate your final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Provide your conclusions about the work you've done, including any limitations or next steps.\n",
    "\n",
    "Questions to consider:\n",
    "\n",
    "- What would you recommend the business do as a result of this work?\n",
    "- How could the stakeholder use your model effectively?\n",
    "- What are some reasons why your analysis might not fully solve the business problem?\n",
    "- What else could you do in the future to improve this project (future work)?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
